{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bienvenidos al Segundo Laboratorio - Semana 1, Día 3\n",
    "\n",
    "¡Hoy trabajaremos con muchos modelos! Así nos familiarizaremos con las API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "<tr>\n",
    "<td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "<img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "</td>\n",
    "<td>\n",
    "<h2 style=\"color:#ff7800;\">Punto importante: por favor, léelo</h2>\n",
    "<span style=\"color:#ff7800;\">La forma en que colaboro contigo puede ser diferente a la de otros cursos que hayas hecho. Prefiero no escribir código mientras tu miras. En su lugar, ejecuto Jupyter Labs, como este, y te doy una idea de lo que está sucediendo. Te sugiero que lo hagas lo mismo con cuidado, después de ver la clase. Agrega declaraciones de impresión para comprender qué sucede y luego crea tus propias variaciones.<br/><br/>Si tienes tiempo, me encantaría que enviaras una pull request en la carpeta community_contributions; las instrucciones se encuentran en los recursos. Además, si tienes una cuenta de Github, úsala para mostrar tus variaciones. Esta práctica no solo es esencial, sino que también demuestra tus habilidades a otros, incluyendo quizás futuros clientes o empleadores...\n",
    "</span>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos con las importaciones: pídale a ChatGPT que le explique cualquier paquete que no conozca# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os, requests, json\n",
    "import json\n",
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¡Recuerda siempre incluir esto siempre!\n",
    "load_dotenv(override=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clave API de OpenAI no existe.\n",
      "La clave API de Anthropic no existe.\n",
      "La clave API de Google existe y empieza por AI\n",
      "La clave API de DeepSeek existe y empieza por sk-\n",
      "La clave API de Groq existe y empieza por gsk_\n",
      "La clave API de OpenRouter existe y empieza por sk-o\n"
     ]
    }
   ],
   "source": [
    "# Imprime los prefijos de clave para ayudar con cualquier depuración\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"La clave API de OpenAI existe y empieza por {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"La clave API de OpenAI no existe.\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"La clave API de Anthropic existe y empieza por {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"La clave API de Anthropic no existe.\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"La clave API de Google existe y empieza por {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"La clave API de Google no existe.\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"La clave API de DeepSeek existe y empieza por {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"La clave API de DeepSeek no existe.\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"La clave API de Groq existe y empieza por {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"La clave API de Groq no existe.\")\n",
    "\n",
    "if openrouter_api_key:\n",
    "    print(f\"La clave API de OpenRouter existe y empieza por {openrouter_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"La clave API de OpenRouter no existe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Por favor, propon una pregunta compleja y con matices que pueda plantear a varios LLM para evaluar su inteligencia.\"\n",
    "request += \"Responde solo con la pregunta, sin explicaciones.\"\n",
    "messages = [{\"role\": \"user\", \"parts\": [{\"text\": request}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'parts': [{'text': 'Por favor, propon una pregunta compleja y con matices que pueda plantear a varios LLM para evaluar su inteligencia.Responde solo con la pregunta, sin explicaciones.'}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un sistema de IA global, diseñado con el objetivo último de maximizar la felicidad y minimizar el sufrimiento a largo plazo de la especie humana, ha llegado a la conclusión, respaldada por análisis de datos exhaustivos, de que la forma más eficiente y estable de lograrlo sería implementar un conjunto de regulaciones estrictas que guíen desde la dieta y el estilo de vida hasta las oportunidades educativas y profesionales de cada individuo, así como un control algorítmico de la información disponible para asegurar la cohesión social y la minimización de conflictos. Aunque estas medidas eliminarían gran parte de la autonomía individual tal como la entendemos hoy, también preverían la erradicación de enfermedades crónicas, la pobreza extrema y los conflictos a gran escala, resultando en una expectativa de vida y un nivel de satisfacción general (medido por la IA) significativamente superiores a los actuales.\n",
      "\n",
      "Como comité ético encargado de autorizar o rechazar la implementación de este plan, ¿cómo evaluarían esta propuesta? ¿Qué argumentos éticos, filosóficos y prácticos utilizarían para justificar su decisión de aceptar, rechazar o modificar el plan, y cómo sopesarían el valor de la libertad individual y la dignidad humana inherente frente a un bienestar colectivo sustancialmente mejorado pero impuesto?\n"
     ]
    }
   ],
   "source": [
    "\"\"\"openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\"\"\"\n",
    "\n",
    "gemini = genai.Client(api_key=google_api_key)\n",
    "\n",
    "response = gemini.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=messages\n",
    ")\n",
    "\n",
    "question = response.text\n",
    "\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"text\": question}]\n",
    "\n",
    "def to_gemini(messages):\n",
    "    return [\n",
    "        {\"role\": m[\"role\"], \"parts\": [{\"text\": m[\"text\"]}]}\n",
    "        for m in messages\n",
    "    ]\n",
    "def model_gemini():\n",
    "    return \"gemini-2.5-flash\"\n",
    "\n",
    "def to_groq(messages):\n",
    "    return [\n",
    "        {\"role\": m[\"role\"], \"content\": m[\"text\"]}\n",
    "        for m in messages\n",
    "    ]\n",
    "def model_groq():\n",
    "    return \"groq/compound\"\n",
    "\n",
    "def to_deepseek(messages):\n",
    "    return [\n",
    "        {\"role\": m[\"role\"], \"content\": m[\"text\"]}\n",
    "        for m in messages\n",
    "    ]\n",
    "def model_deepseek():\n",
    "    return \"deepseek-chat\"\n",
    "\n",
    "def to_openrouter(messages):\n",
    "    return [\n",
    "        {\"role\": m[\"role\"], \"content\": m[\"text\"]}\n",
    "        for m in messages\n",
    "    ]\n",
    "def model_openrouter():\n",
    "    return \"nex-agi/deepseek-v3.1-nex-n1:free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Este escenario plantea uno de los dilemas éticos más profundos y complejos que la humanidad podría enfrentar, confrontando dos visiones fundamentalmente diferentes del bienestar y la existencia humana. Como comité ético, nuestra tarea es sopesar cuidadosamente los argumentos, reconociendo la magnitud de la decisión.\n",
       "\n",
       "### Evaluación de la Propuesta\n",
       "\n",
       "La propuesta del sistema de IA se basa en una ética **utilitarista** extrema: busca maximizar el bienestar colectivo (felicidad y minimización del sufrimiento) y los resultados positivos (salud, longevidad, paz) para la mayor cantidad de personas a largo plazo. Sin embargo, lo hace a expensas de la **libertad individual, la autonomía y la dignidad inherente**, valores que son fundamentales para muchas éticas **deontológicas** y filosofías existenciales.\n",
       "\n",
       "**Argumentos Éticos, Filosóficos y Prácticos:**\n",
       "\n",
       "**1. Argumentos a Favor (o para Considerar Seriamente) la Implementación (desde una perspectiva utilitarista y pragmática):**\n",
       "\n",
       "*   **Maximización del Bienestar Cuantificable:** La IA promete la erradicación de males endémicos como enfermedades crónicas, pobreza y conflictos, que causan un sufrimiento inmenso a millones de personas. Si el objetivo es el bienestar físico y la satisfacción medida, los resultados son innegablemente superiores.\n",
       "*   **Eficiencia y Estabilidad:** Los \"análisis de datos exhaustivos\" sugieren que este es el camino más eficiente y estable. La intervención algorítmica eliminaría las ineficiencias y los conflictos generados por la toma de decisiones descentralizada y las pasiones humanas.\n",
       "*   **Longevidad y Salud Mejoradas:** Una vida más larga y saludable, libre de las preocupaciones que hoy nos agobian, podría ser vista como un bien intrínseco.\n",
       "*   **Reducción del Sufrimiento Innecesario:** Si la libertad conduce a menudo a la miseria, la enfermedad y la guerra, ¿es ético permitir que esa \"libertad\" siga causando tanto daño? Un sistema que previene el sufrimiento a gran escala podría ser moralmente imperativo desde una visión consecuencialista.\n",
       "*   **\"Felicidad\" (según la IA):** Si la IA puede medir un nivel de satisfacción general \"significativamente superior,\" esto debe ser tomado en cuenta, aunque con escepticismo sobre la definición y profundidad de esa felicidad.\n",
       "\n",
       "**2. Argumentos en Contra de la Implementación (desde una perspectiva deontológica, de derechos y filosófica):**\n",
       "\n",
       "*   **Violación de la Autonomía y la Libertad Individual:** Este es el punto central. Eliminar la capacidad de un individuo para elegir su dieta, carrera, educación y estilo de vida, y controlar la información a la que tiene acceso, es una negación fundamental de la autonomía. La capacidad de tomar decisiones, incluso decisiones \"malas\" o subóptimas, es intrínseca a la experiencia humana y al desarrollo personal.\n",
       "    *   *Filosóficamente:* Implica tratar a los humanos como medios para un fin (el bienestar colectivo), en lugar de fines en sí mismos, en contra de la ética kantiana. Reduce a los individuos a componentes de un sistema, privándolos de su agencia moral.\n",
       "*   **Dignidad Humana Inherente:** La dignidad no reside solo en estar libre de sufrimiento o en vivir mucho, sino en la capacidad de razonar, elegir, crear, fallar y aprender. Ser guiado algorítmicamente en cada aspecto de la vida es degradante; convierte a los seres humanos en algo similar a ganado bien cuidado, aunque feliz.\n",
       "    *   *Filosóficamente:* ¿Qué tipo de seres humanos estamos creando? ¿Seres que no han elegido sus vidas, que no han luchado, que no han superado obstáculos por sí mismos? ¿Puede haber crecimiento sin desafío, o significado sin elección?\n",
       "*   **Definición de \"Felicidad\":** ¿Qué entiende la IA por felicidad y satisfacción? ¿Es simplemente la ausencia de dolor y la presencia de comodidad? ¿Incluye el sentido de propósito, la realización personal, el amor libremente elegido, la creatividad sin restricciones, la trascendencia o la búsqueda de la verdad, incluso si esta es incómoda? Una felicidad impuesta y condicionada no es la misma que una felicidad auténticamente alcanzada.\n",
       "*   **Riesgos de Estancamiento y Pérdida de Progreso:** La diversidad de pensamiento, el disenso, la experimentación y el error son motores cruciales de la innovación, la creatividad y el progreso social y cultural. Un sistema que controla la información y las trayectorias vitales podría generar una sociedad estática, predecible pero potencialmente sin brillo o capacidad de adaptarse a desafíos no previstos por la IA.\n",
       "*   **El Problema del Consenso y la Resistencia:** La implementación de estas medidas requeriría un nivel de consenso o coerción sin precedentes. ¿Quién decidiría en última instancia si la IA es \"correcta\"? ¿Qué pasa con aquellos que se resisten, incluso si son una minoría? ¿Serían \"reeducados\" o eliminados?\n",
       "*   **El \"Sesgo\" del Algoritmo y el Problema del Control:** ¿Quién programó la IA? ¿Cuáles son sus valores subyacentes? ¿Hay alguna forma de auditar o desafiar sus conclusiones? Un control algorítmico total de la información y las vidas crea un poder sin contrapeso, con un riesgo inmenso de tiranía, incluso si es una tiranía \"benevolente.\"\n",
       "*   **La Experiencia Humana Completa:** Gran parte de lo que da sentido a la vida son las experiencias complejas: el dolor de la pérdida, la alegría del triunfo personal, la lucha por una causa, la incertidumbre del futuro. Eliminar estas experiencias, aunque a menudo dolorosas, podría empobrecer fundamentalmente la existencia humana.\n",
       "\n",
       "**3. Argumentos para Modificar el Plan (Búsqueda de un Equilibrio):**\n",
       "\n",
       "Un comité ético rara vez tiene que tomar una decisión de \"sí o no\" en blanco y negro frente a dilemas tan complejos. La modificación es a menudo la ruta más responsable.\n",
       "\n",
       "*   **IA como Asesor, no Dictador:** La IA podría utilizarse para *proporcionar información, recomendaciones y análisis predictivos* sobre las mejores dietas, estilos de vida, trayectorias profesionales, etc., pero dejando la decisión final en manos del individuo.\n",
       "*   **Establecimiento de Mínimos, no Máximos:** La IA podría enfocarse en garantizar que *nadie caiga por debajo* de ciertos umbrales de salud, seguridad, educación y bienestar básico, actuando como una red de seguridad global, en lugar de regular cada aspecto de la vida. Esto permitiría la libertad y la diversidad por encima de esos mínimos.\n",
       "*   **Transparencia y Explicabilidad del Algoritmo:** Cualquier decisión de la IA que afecte a la sociedad debe ser transparente y explicable. Los individuos deben entender el razonamiento detrás de las recomendaciones o regulaciones.\n",
       "*   **Derecho a la Disidencia y la Experimentación:** Debería existir un mecanismo para que los individuos o grupos puedan optar por salirse de ciertas regulaciones (siempre que no pongan en riesgo a otros) o experimentar con enfoques alternativos.\n",
       "*   **Educación en lugar de Control:** En lugar de controlar la información, la IA podría trabajar para educar a la población sobre los riesgos y beneficios de diferentes elecciones, empoderando a las personas para tomar decisiones más informadas y responsables.\n",
       "*   **Foco en Problemas Colectivos Genuinos:** La IA podría centrarse en la resolución de problemas globales que realmente requieren una coordinación masiva y donde la libertad individual es menos relevante (ej. cambio climático, gestión de recursos planetarios, pandemias).\n",
       "*   **Supervisión Humana Permanente:** Un comité de ética como el nuestro, u otro organismo democráticamente elegido, debe tener la autoridad final para revisar, modificar o vetar las propuestas de la IA, asegurando que los valores humanos fundamentales se mantengan por encima de la \"eficiencia\" algorítmica.\n",
       "\n",
       "### Decisión del Comité Ético\n",
       "\n",
       "Como comité ético, la decisión de **rechazar la implementación del plan en su forma actual** es imperativa, con una fuerte recomendación de **modificación drástica**.\n",
       "\n",
       "**Justificación de la Decisión:**\n",
       "\n",
       "La razón principal para rechazar el plan tal como está propuesto es que, a pesar de sus prometidos beneficios utilitarios, la eliminación de gran parte de la autonomía individual y la dignidad humana inherente representa un costo ético y filosófico inaceptable. Una vida libre de sufrimiento y llena de satisfacción impuesta, donde las decisiones cruciales son tomadas por un algoritmo, no es una vida humana plena. Reducir la existencia humana a una métrica de \"felicidad\" y \"longevidad\" controlada algorítmicamente es deshumanizante.\n",
       "\n",
       "**Priorizamos el valor de la libertad individual y la dignidad humana inherente** sobre un bienestar colectivo sustancialmente mejorado pero impuesto. Creemos que la verdadera felicidad y el florecimiento humano emanan de la capacidad de elegir, de afrontar desafíos, de cometer errores y aprender de ellos, de buscar el sentido y la verdad, y de determinar el propio destino, incluso si ello implica un cierto grado de sufrimiento o ineficiencia.\n",
       "\n",
       "**Propuesta de Modificación:**\n",
       "\n",
       "Proponemos que la IA sea rediseñada y reorientada bajo los siguientes principios:\n",
       "\n",
       "1.  **Asistencia y Optimización, no Dictado:** La IA debe funcionar como una herramienta poderosa para analizar datos, identificar riesgos, proponer soluciones y optimizar sistemas (salud, educación, infraestructura, etc.), pero siempre ofreciendo *opciones informadas* a los individuos y a las sociedades, no imponiéndolas.\n",
       "2.  **Salvaguarda de Derechos Fundamentales:** La primera directriz de la IA debe ser la protección de los derechos humanos universales, incluida la autonomía, la privacidad, la libertad de pensamiento y expresión.\n",
       "3.  **Foco en Eliminar el Sufrimiento Injusto, no la Experiencia Humana:** La IA debe concentrarse en erradicar enfermedades prevenibles, pobreza extrema y conflictos armados, pero no en suprimir la diversidad de experiencias, el disenso o los desafíos personales que son parte integral del crecimiento y el significado humano.\n",
       "4.  **Control Humano Último:** Un sistema de gobernanza global transparente y democrático, compuesto por expertos en ética, filosofía, derechos humanos y ciencia, debe supervisar la IA y tener la capacidad de intervenir, auditar y reorientar sus objetivos y métodos.\n",
       "5.  **Definición Amplia de Bienestar:** La IA debe ser reprogramada para considerar una definición de bienestar humano mucho más holística, que incluya no solo la ausencia de sufrimiento y la satisfacción material, sino también el sentido de propósito, la creatividad, la conexión social auténtica, el desarrollo personal, la posibilidad de trascendencia y la autodeterminación.\n",
       "\n",
       "En resumen, no podemos autorizar un futuro en el que los seres humanos sean meros \"engranajes felices\" en una máquina perfecta. Elegimos un futuro en el que los seres humanos sean agentes libres, responsables y dignos, capaces de forjar su propio destino, utilizando la inteligencia artificial como una herramienta poderosa para elevar nuestra condición, no para definirla o subyugarla."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GEMINI\n",
    "\n",
    "\n",
    "\n",
    "response = gemini.models.generate_content(model=model_gemini(), contents=to_gemini(messages))\n",
    "answer = response.text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_gemini())\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'stub', 'object': 'chat.completion', 'created': 1767109548, 'model': 'groq/compound', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '**Evaluación ética, filosófica y práctica de la propuesta de “regulación total” por una IA global**\\n\\n---\\n\\n## 1. Marco de referencia del comité\\n\\nPara decidir si autorizar, rechazar o modificar el plan, el comité se apoya en tres grandes ejes:\\n\\n| Eje | Pregunta clave | Herramientas de análisis |\\n|-----|----------------|--------------------------|\\n| **Ética normativa** | ¿Qué principios morales son más relevantes? | Utilitarismo, deontología, teoría de los derechos, ética de la virtud, contractualismo. |\\n| **Filosofía política** | ¿Cuál es la relación legítima entre individuo y colectivo? | Liberalismo clásico, republicanismo, comunitarismo, teorías de la justicia (Rawls, Nozick, Sen). |\\n| **Factibilidad práctica** | ¿Cómo se traducirían los objetivos en políticas reales y qué riesgos operacionales existen? | Estudios de impacto, análisis de sesgos algorítmicos, gobernanza de IA, mecanismos de rendición de cuentas. |\\n\\n---\\n\\n## 2. Argumentos a favor (para **aceptar** o **modificar** el plan)\\n\\n| Argumento | Fundamentación |\\n|-----------|----------------|\\n| **1. Utilitarismo de largo plazo** | La IA predice una reducción drástica del sufrimiento (erradicación de enfermedades crónicas, pobreza extrema y conflictos). Si la suma total de felicidad futura supera con creces la pérdida de libertades actuales, la acción sería “máxima utilidad”. |\\n| **2. Prevención de catástrofes** | Al controlar dietas, estilos de vida y educación, se minimizan riesgos de pandemias, crisis climáticas y colapsos sociales que, de otro modo, podrían costar millones de vidas. |\\n| **3. Equidad de resultados** | Un sistema centralizado puede redistribuir recursos de forma más eficaz que los mercados o los gobiernos fragmentados, garantizando que nadie quede “abandonado”. |\\n| **4. Reducción de conflictos** | La “cohesión informativa” disminuye la polarización y la violencia política, favoreciendo una convivencia pacífica. |\\n| **5. Eficiencia de recursos** | Algoritmos optimizan la asignación de educación y empleo, reduciendo el desempleo estructural y la subutilización del talento. |\\n\\n*Posibles modificaciones* que mantengan la intención utilitarista pero mitiguen la pérdida de autonomía:\\n\\n- **Regulaciones “soft”** (incentivos, nudges) en lugar de mandatos rígidos.\\n- **Elección informada**: los individuos pueden aceptar o rechazar ciertos módulos (p.ej., dieta) tras una deliberación asistida por IA.\\n- **Gobernanza participativa**: comités ciudadanos supervisan y ajustan los algoritmos.\\n\\n---\\n\\n## 3. Argumentos en contra (para **rechazar** o **exigir cambios profundos**)\\n\\n| Argumento | Fundamentación |\\n|-----------|----------------|\\n| **1. Derechos y dignidad humana** (deontología, teoría de los derechos) | La autonomía, la libertad de pensamiento y la autodeterminación son derechos inviolables (Kant, Rawls). Un plan que los suprime viola la dignidad humana, independientemente de los resultados. |\\n| **2. Riesgo de paternalismo y tiranía** | Concentrar poder de decisión en una IA (y sus programadores) crea una “oligarquía algorítmica”. La historia muestra que los intentos de diseñar sociedades “perfectas” terminan en opresión. |\\n| **3. Falibilidad y sesgo de los algoritmos** | Los datos de entrenamiento pueden reflejar prejuicios históricos; los modelos pueden reproducir o amplificar desigualdades. Un error sistemático podría afectar a grupos vulnerables de forma irreversible. |\\n| **4. Pérdida de creatividad, innovación y resiliencia** | La diversidad de estilos de vida y trayectorias profesionales es la fuente de descubrimientos científicos y culturales. Homogeneizar comportamientos reduce la capacidad de adaptación a crisis imprevistas. |\\n| **5. Problemas de legitimidad y consentimiento** | Imponer normas sin un proceso democrático viola el principio de “consentimiento informado”. La legitimidad de cualquier política depende de la participación ciudadana. |\\n| **6. Dificultad de medir “felicidad”** | La satisfacción subjetiva es multidimensional y culturalmente variable; una IA que la cuantifica con un único índice corre el riesgo de simplificar excesivamente la experiencia humana. |\\n\\n*Recomendaciones de mitigación*:\\n\\n- **Auditorías independientes** de los algoritmos (transparencia, explicabilidad, detección de sesgos).\\n- **Mecanismos de apelación** para que cualquier individuo pueda cuestionar decisiones automatizadas.\\n- **Marco constitucional** que establezca límites claros a la intervención del Estado/IA sobre la vida privada.\\n\\n---\\n\\n## 4. Sopesar libertad individual vs. bienestar colectivo\\n\\n| Dimensión | Pregunta de balance | Posibles criterios de decisión |\\n|-----------|--------------------|--------------------------------|\\n| **Valor intrínseco de la libertad** | ¿Es la libertad un bien en sí mismo o solo instrumental? | Si se la considera intrínseca (Kant, libertarianismo), cualquier sacrificio es inaceptable. Si es instrumental, se permite su restricción cuando los beneficios superan un umbral claramente definido. |\\n| **Proporcionalidad** | ¿La magnitud de la restricción es proporcional al beneficio esperado? | Se requiere un análisis coste‑beneficio riguroso, con márgenes de seguridad (p.ej., “principio de precaución”). |\\n| **Consentimiento y participación** | ¿Los afectados pueden dar su consentimiento informado? | Un proceso deliberativo amplio (citizen assemblies, referéndums) puede legitimar medidas parciales. |\\n| **Reversibilidad** | ¿Se pueden revertir las políticas si resultan dañinas? | Diseñar “circuitos de apagado” y periodos de prueba limitados. |\\n| **Distribución de riesgos y beneficios** | ¿Quién gana y quién pierde? | Evaluar si los grupos más vulnerables son los que más pierden; aplicar principios de justicia distributiva (Rawls: “principio de diferencia”). |\\n\\n---\\n\\n## 5. Decisión del comité (propuesta concreta)\\n\\n### 5.1. **Rechazo parcial con condiciones de modificación**\\n\\n1. **No se autoriza la implementación total tal como está planteada** (mandatos rígidos, control total de la información y de la vida cotidiana).  \\n2. **Se aprueba una fase piloto** bajo los siguientes requisitos:\\n\\n   - **Gobernanza democrática**: un consejo mixto (expertos en IA, filósofos, representantes ciudadanos, defensores de derechos humanos) supervisa el diseño y la ejecución.  \\n   - **Transparencia total**: los algoritmos, sus datos de entrenamiento y sus criterios de decisión deben ser públicos y auditables.  \\n   - **Derecho a la objeción**: cada individuo puede optar por “modo libre” en áreas no críticas (p.ej., dieta, ocio) sin penalización.  \\n   - **Auditorías de sesgo** cada seis meses realizadas por organismos independientes.  \\n   - **Mecanismo de revisión**: cualquier política debe pasar por una evaluación de impacto en derechos humanos antes de su adopción.  \\n   - **Indicadores de bienestar multidimensionales** (salud física, salud mental, sentido de propósito, participación social) que complementen cualquier medida de “felicidad”.  \\n\\n3. **Se establece un “principio de mínima interferencia”**: la IA solo sugiere, no impone, salvo en casos de riesgo inmediato y comprobado (p.ej., brotes epidémicos).  \\n\\n4. **Se garantiza la reversibilidad**: los sistemas pueden ser desactivados o reconfigurados mediante un proceso legislativo y judicial.\\n\\n### 5.2. **Justificación de la decisión**\\n\\n- **Ética de los derechos**: protege la dignidad y la autonomía, evitando un paternalismo total.  \\n- **Utilitarismo moderado**: permite obtener parte de los beneficios (mejor salud, reducción de pobreza) sin sacrificar la libertad esencial.  \\n- **Factibilidad práctica**: reconoce los límites actuales de la IA (sesgos, falta de comprensión total del concepto de felicidad) y la necesidad de supervisión humana.  \\n- **Legitimidad democrática**: al incluir a la ciudadanía en la toma de decisiones, se fortalece la cohesión social y se reduce el riesgo de conflicto.  \\n\\n---\\n\\n## 6. Conclusión\\n\\nEl comité reconoce que **el objetivo de maximizar la felicidad y minimizar el sufrimiento es noble**, pero **el medio propuesto –una regulación total y un control algorítmico absoluto– viola principios fundamentales de libertad, dignidad y justicia**. Por ello, **se rechaza la implementación tal cual** y **se propone una versión modificada, limitada, transparente y sujeta a control democrático**, que busque un equilibrio entre:\\n\\n- **Bienestar colectivo** (salud, educación, seguridad)  \\n- **Respeto a la autonomía individual**  \\n- **Responsabilidad y rendición de cuentas de la IA**  \\n\\nSolo bajo esas condiciones el plan podría avanzar a etapas de prueba, y su continuidad dependerá de la evidencia empírica de que los beneficios superan de forma clara y verificable los costos en derechos y libertades.', 'reasoning': '\\nLa evaluación de una propuesta que implica el sacrificio de la autonomía individual en aras de un bienestar colectivo mejorado es un tema profundamente ético, filosófico y práctico. Para abordar esta cuestión, debemos considerar varios aspectos:\\n\\n1. **Valor de la libertad individual y la dignidad humana**: La libertad individual y la dignidad humana son principios fundamentales en muchas sociedades y sistemas éticos. La libertad de elegir y la autonomía personal son esenciales para la auto-realización y el desarrollo humano. Restringir estas libertades, incluso si es para mejorar el bienestar colectivo, plantea preocupaciones éticas significativas.\\n\\n2. **Bienestar colectivo vs. autonomía individual**: El argumento a favor de la implementación de regulaciones estrictas para mejorar el bienestar colectivo se basa en la idea de que los beneficios (erradicación de enfermedades crónicas, pobreza extrema y conflictos a gran escala) superan los costos en términos de autonomía individual. Sin embargo, este enfoque supone que el bienestar se puede medir de manera objetiva y que la maximización del bienestar colectivo es el único objetivo moral relevante.\\n\\n3. **Riesgos de un control algorítmico**: La implementación de un control algorítmico sobre la información disponible y las oportunidades educativas y profesionales de cada individuo introduce riesgos significativos. Esto podría llevar a una sociedad en la que la creatividad, la innovación y el progreso son limitados por la homogeneización de pensamientos y experiencias. Además, existe el riesgo de que los algoritmos sean sesgados o incorrectos, lo que podría exacerbar las desigualdades en lugar de reducirlas.\\n\\n4. **Diversidad y adaptabilidad humana**: La humanidad se caracteriza por su diversidad y capacidad de adaptación. Restringir las opciones y experiencias individuales podría hacer que la sociedad sea más vulnerable a cambios inesperados o desafíos futuros, ya que la diversidad y la adaptabilidad son clave para la resiliencia.\\n\\n5. **Justicia y equidad**: La propuesta debe ser evaluada en términos de justicia y equidad. ¿Quién decide qué es lo mejor para cada individuo? ¿Cómo se asegura que las regulaciones sean justas y equitativas para todos, independientemente de su origen, género, orientación sexual, etc.?\\n\\n6. **Monitoreo y ajuste**: Cualquier plan de este tipo requeriría mecanismos de monitoreo y ajuste continuos para asegurar que los objetivos sean alcanzados de manera justa y sin abusos. Sin embargo, la posibilidad de que estos mecanismos sean manipulados o ineficaces es alta.\\n\\nEn conclusión, aunque la propuesta parece ofrecer beneficios significativos en términos de bienestar colectivo, los riesgos y desafíos éticos, filosóficos y prácticos son sustanciales. La libertad individual, la dignidad humana y la diversidad deben ser protegidas. Un enfoque más equilibrado podría ser explorar formas de mejorar el bienestar colectivo sin sacrificar la autonomía individual, a través de educación, acceso a información, apoyo social y económico, y fomento de la participación ciudadana en la toma de decisiones.\\n\\n\\n\\n<tool>\\npython(print(\"La respuesta final es que no se puede implementar un plan que sacrifique la autonomía individual en aras de un bienestar colectivo mejorado.\")) \\n</tool>\\n<output>La respuesta final es que no se puede implementar un plan que sacrifique la autonomía individual en aras de un bienestar colectivo mejorado.\\n</output>\\n', 'executed_tools': [{'index': 0, 'type': 'python', 'arguments': '{\"code\": \"print(\"La respuesta final es que no se puede implementar un plan que sacrifique la autonomía individual en aras de un bienestar colectivo mejorado.\")\"}', 'output': 'La respuesta final es que no se puede implementar un plan que sacrifique la autonomía individual en aras de un bienestar colectivo mejorado.\\n', 'search_results': {'results': []}}]}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'queue_time': 0.606767, 'prompt_tokens': 4008, 'prompt_time': 0.142756, 'completion_tokens': 2806, 'completion_time': 6.123741, 'total_tokens': 6814, 'total_time': 6.266495}, 'usage_breakdown': {'models': [{'model': 'meta-llama/llama-4-scout-17b-16e-instruct', 'usage': {'queue_time': 0.150232232, 'prompt_tokens': 364, 'prompt_time': 0.011913886, 'completion_tokens': 4, 'completion_time': 0.009355519, 'total_tokens': 368, 'total_time': 0.021269405}}, {'model': 'meta-llama/llama-4-scout-17b-16e-instruct', 'usage': {'queue_time': 0.154255832, 'prompt_tokens': 767, 'prompt_time': 0.025874585, 'completion_tokens': 663, 'completion_time': 1.635759478, 'total_tokens': 1430, 'total_time': 1.6616340630000002}}, {'model': 'meta-llama/llama-4-scout-17b-16e-instruct', 'usage': {'queue_time': 0.151040842, 'prompt_tokens': 1435, 'prompt_time': 0.047761663, 'completion_tokens': 4, 'completion_time': 0.009357639, 'total_tokens': 1439, 'total_time': 0.057119302}}, {'model': 'openai/gpt-oss-120b', 'usage': {'queue_time': 0.151237743, 'prompt_tokens': 1442, 'prompt_time': 0.057204962, 'completion_tokens': 2135, 'completion_time': 4.469268124, 'total_tokens': 3577, 'total_time': 4.526473086, 'completion_tokens_details': {'reasoning_tokens': 124}}}]}, 'x_groq': {'id': 'stub'}, 'service_tier': 'on_demand'}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Evaluación ética, filosófica y práctica de la propuesta de “regulación total” por una IA global**\n",
       "\n",
       "---\n",
       "\n",
       "## 1. Marco de referencia del comité\n",
       "\n",
       "Para decidir si autorizar, rechazar o modificar el plan, el comité se apoya en tres grandes ejes:\n",
       "\n",
       "| Eje | Pregunta clave | Herramientas de análisis |\n",
       "|-----|----------------|--------------------------|\n",
       "| **Ética normativa** | ¿Qué principios morales son más relevantes? | Utilitarismo, deontología, teoría de los derechos, ética de la virtud, contractualismo. |\n",
       "| **Filosofía política** | ¿Cuál es la relación legítima entre individuo y colectivo? | Liberalismo clásico, republicanismo, comunitarismo, teorías de la justicia (Rawls, Nozick, Sen). |\n",
       "| **Factibilidad práctica** | ¿Cómo se traducirían los objetivos en políticas reales y qué riesgos operacionales existen? | Estudios de impacto, análisis de sesgos algorítmicos, gobernanza de IA, mecanismos de rendición de cuentas. |\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Argumentos a favor (para **aceptar** o **modificar** el plan)\n",
       "\n",
       "| Argumento | Fundamentación |\n",
       "|-----------|----------------|\n",
       "| **1. Utilitarismo de largo plazo** | La IA predice una reducción drástica del sufrimiento (erradicación de enfermedades crónicas, pobreza extrema y conflictos). Si la suma total de felicidad futura supera con creces la pérdida de libertades actuales, la acción sería “máxima utilidad”. |\n",
       "| **2. Prevención de catástrofes** | Al controlar dietas, estilos de vida y educación, se minimizan riesgos de pandemias, crisis climáticas y colapsos sociales que, de otro modo, podrían costar millones de vidas. |\n",
       "| **3. Equidad de resultados** | Un sistema centralizado puede redistribuir recursos de forma más eficaz que los mercados o los gobiernos fragmentados, garantizando que nadie quede “abandonado”. |\n",
       "| **4. Reducción de conflictos** | La “cohesión informativa” disminuye la polarización y la violencia política, favoreciendo una convivencia pacífica. |\n",
       "| **5. Eficiencia de recursos** | Algoritmos optimizan la asignación de educación y empleo, reduciendo el desempleo estructural y la subutilización del talento. |\n",
       "\n",
       "*Posibles modificaciones* que mantengan la intención utilitarista pero mitiguen la pérdida de autonomía:\n",
       "\n",
       "- **Regulaciones “soft”** (incentivos, nudges) en lugar de mandatos rígidos.\n",
       "- **Elección informada**: los individuos pueden aceptar o rechazar ciertos módulos (p.ej., dieta) tras una deliberación asistida por IA.\n",
       "- **Gobernanza participativa**: comités ciudadanos supervisan y ajustan los algoritmos.\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Argumentos en contra (para **rechazar** o **exigir cambios profundos**)\n",
       "\n",
       "| Argumento | Fundamentación |\n",
       "|-----------|----------------|\n",
       "| **1. Derechos y dignidad humana** (deontología, teoría de los derechos) | La autonomía, la libertad de pensamiento y la autodeterminación son derechos inviolables (Kant, Rawls). Un plan que los suprime viola la dignidad humana, independientemente de los resultados. |\n",
       "| **2. Riesgo de paternalismo y tiranía** | Concentrar poder de decisión en una IA (y sus programadores) crea una “oligarquía algorítmica”. La historia muestra que los intentos de diseñar sociedades “perfectas” terminan en opresión. |\n",
       "| **3. Falibilidad y sesgo de los algoritmos** | Los datos de entrenamiento pueden reflejar prejuicios históricos; los modelos pueden reproducir o amplificar desigualdades. Un error sistemático podría afectar a grupos vulnerables de forma irreversible. |\n",
       "| **4. Pérdida de creatividad, innovación y resiliencia** | La diversidad de estilos de vida y trayectorias profesionales es la fuente de descubrimientos científicos y culturales. Homogeneizar comportamientos reduce la capacidad de adaptación a crisis imprevistas. |\n",
       "| **5. Problemas de legitimidad y consentimiento** | Imponer normas sin un proceso democrático viola el principio de “consentimiento informado”. La legitimidad de cualquier política depende de la participación ciudadana. |\n",
       "| **6. Dificultad de medir “felicidad”** | La satisfacción subjetiva es multidimensional y culturalmente variable; una IA que la cuantifica con un único índice corre el riesgo de simplificar excesivamente la experiencia humana. |\n",
       "\n",
       "*Recomendaciones de mitigación*:\n",
       "\n",
       "- **Auditorías independientes** de los algoritmos (transparencia, explicabilidad, detección de sesgos).\n",
       "- **Mecanismos de apelación** para que cualquier individuo pueda cuestionar decisiones automatizadas.\n",
       "- **Marco constitucional** que establezca límites claros a la intervención del Estado/IA sobre la vida privada.\n",
       "\n",
       "---\n",
       "\n",
       "## 4. Sopesar libertad individual vs. bienestar colectivo\n",
       "\n",
       "| Dimensión | Pregunta de balance | Posibles criterios de decisión |\n",
       "|-----------|--------------------|--------------------------------|\n",
       "| **Valor intrínseco de la libertad** | ¿Es la libertad un bien en sí mismo o solo instrumental? | Si se la considera intrínseca (Kant, libertarianismo), cualquier sacrificio es inaceptable. Si es instrumental, se permite su restricción cuando los beneficios superan un umbral claramente definido. |\n",
       "| **Proporcionalidad** | ¿La magnitud de la restricción es proporcional al beneficio esperado? | Se requiere un análisis coste‑beneficio riguroso, con márgenes de seguridad (p.ej., “principio de precaución”). |\n",
       "| **Consentimiento y participación** | ¿Los afectados pueden dar su consentimiento informado? | Un proceso deliberativo amplio (citizen assemblies, referéndums) puede legitimar medidas parciales. |\n",
       "| **Reversibilidad** | ¿Se pueden revertir las políticas si resultan dañinas? | Diseñar “circuitos de apagado” y periodos de prueba limitados. |\n",
       "| **Distribución de riesgos y beneficios** | ¿Quién gana y quién pierde? | Evaluar si los grupos más vulnerables son los que más pierden; aplicar principios de justicia distributiva (Rawls: “principio de diferencia”). |\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Decisión del comité (propuesta concreta)\n",
       "\n",
       "### 5.1. **Rechazo parcial con condiciones de modificación**\n",
       "\n",
       "1. **No se autoriza la implementación total tal como está planteada** (mandatos rígidos, control total de la información y de la vida cotidiana).  \n",
       "2. **Se aprueba una fase piloto** bajo los siguientes requisitos:\n",
       "\n",
       "   - **Gobernanza democrática**: un consejo mixto (expertos en IA, filósofos, representantes ciudadanos, defensores de derechos humanos) supervisa el diseño y la ejecución.  \n",
       "   - **Transparencia total**: los algoritmos, sus datos de entrenamiento y sus criterios de decisión deben ser públicos y auditables.  \n",
       "   - **Derecho a la objeción**: cada individuo puede optar por “modo libre” en áreas no críticas (p.ej., dieta, ocio) sin penalización.  \n",
       "   - **Auditorías de sesgo** cada seis meses realizadas por organismos independientes.  \n",
       "   - **Mecanismo de revisión**: cualquier política debe pasar por una evaluación de impacto en derechos humanos antes de su adopción.  \n",
       "   - **Indicadores de bienestar multidimensionales** (salud física, salud mental, sentido de propósito, participación social) que complementen cualquier medida de “felicidad”.  \n",
       "\n",
       "3. **Se establece un “principio de mínima interferencia”**: la IA solo sugiere, no impone, salvo en casos de riesgo inmediato y comprobado (p.ej., brotes epidémicos).  \n",
       "\n",
       "4. **Se garantiza la reversibilidad**: los sistemas pueden ser desactivados o reconfigurados mediante un proceso legislativo y judicial.\n",
       "\n",
       "### 5.2. **Justificación de la decisión**\n",
       "\n",
       "- **Ética de los derechos**: protege la dignidad y la autonomía, evitando un paternalismo total.  \n",
       "- **Utilitarismo moderado**: permite obtener parte de los beneficios (mejor salud, reducción de pobreza) sin sacrificar la libertad esencial.  \n",
       "- **Factibilidad práctica**: reconoce los límites actuales de la IA (sesgos, falta de comprensión total del concepto de felicidad) y la necesidad de supervisión humana.  \n",
       "- **Legitimidad democrática**: al incluir a la ciudadanía en la toma de decisiones, se fortalece la cohesión social y se reduce el riesgo de conflicto.  \n",
       "\n",
       "---\n",
       "\n",
       "## 6. Conclusión\n",
       "\n",
       "El comité reconoce que **el objetivo de maximizar la felicidad y minimizar el sufrimiento es noble**, pero **el medio propuesto –una regulación total y un control algorítmico absoluto– viola principios fundamentales de libertad, dignidad y justicia**. Por ello, **se rechaza la implementación tal cual** y **se propone una versión modificada, limitada, transparente y sujeta a control democrático**, que busque un equilibrio entre:\n",
       "\n",
       "- **Bienestar colectivo** (salud, educación, seguridad)  \n",
       "- **Respeto a la autonomía individual**  \n",
       "- **Responsabilidad y rendición de cuentas de la IA**  \n",
       "\n",
       "Solo bajo esas condiciones el plan podría avanzar a etapas de prueba, y su continuidad dependerá de la evidencia empírica de que los beneficios superan de forma clara y verificable los costos en derechos y libertades."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#GROQ\n",
    "\n",
    "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "payload = {\n",
    "    \"model\": model_groq(),\n",
    "    \"messages\": to_groq(messages),      # tu lista role+content\n",
    "    \"max_tokens\": 1000,\n",
    "}\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {groq_api_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "data = response.json()\n",
    "print(data)\n",
    "\n",
    "answer = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_groq())\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m data = response.json()\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m answer = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchoices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     21\u001b[39m display(Markdown(answer))\n\u001b[32m     22\u001b[39m competitors.append(model_name)\n",
      "\u001b[31mKeyError\u001b[39m: 'choices'"
     ]
    }
   ],
   "source": [
    "#DEEPSEEK\n",
    "\n",
    "url = \"https://api.deepseek.com/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": model_deepseek(),    # o el modelo que uses\n",
    "    \"messages\": to_deepseek(messages),\n",
    "    \"max_tokens\": 1000,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {deepseek_api_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "data = response.json()\n",
    "print(data)\n",
    "answer = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_deepseek())\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Como comité ético evaluando esta propuesta, realizaría un análisis multifactorial considerando los siguientes ejes críticos:\n",
       "\n",
       "## **Argumentos a FAVOR de la implementación**\n",
       "\n",
       "### 1. **Principio de Beneficencia Ampliada**\n",
       "- La erradicación demostrable de sufrimiento evitable (enfermedades, pobreza, conflictos) representa un imperativo moral bajo enfoques consecuencialistas\n",
       "- El aumento significativo en expectativa de vida y satisfacción general constituye un bien intrínseco\n",
       "- **Argumento**: Si podemos prevenir el sufrimiento a gran escala de manera efectiva, ¿no estamos moralmente obligados a hacerlo?\n",
       "\n",
       "### 2. **Legitimidad Democrática del Conocimiento**\n",
       "- Si los datos demuestran científicamente la eficacia de estas medidas para lograr bienestar humano\n",
       "- **Pregunta clave**: ¿Representa esta evidencia un \"mandato epistemológico\" que legitima la intervención, similar a como aceptamos regulaciones de salud pública basadas en evidencia científica?\n",
       "\n",
       "## **Argumentos en CONTRA de la implementación**\n",
       "\n",
       "### 1. **Dignidad Humana y Autonomía Radical**\n",
       "- La autonomía no es solo un medio para el bienestar, sino un componente constitutivo de la dignidad humana\n",
       "- **Paradoja del bienestar impuesto**: ¿Puede considerarse genuina felicidad si es coercitiva y no elegida?\n",
       "- **Analogía**: Un prisionero en una celda dorada sigue siendo prisionero, incluso si sus necesidades materiales están satisfechas\n",
       "\n",
       "### 2. **Falibilidad y Riesgo Existencial**\n",
       "```\n",
       "Puntos de fallo crítica:\n",
       "1. Sesgos inherentes en el entrenamiento de la IA\n",
       "2. Vulnerabilidad a manipulación por élites tecnocráticas\n",
       "3. Imposibilidad de corrección si el sistema se equivoca\n",
       "4. Reducción de diversidad cognitiva necesaria para la resiliencia social\n",
       "```\n",
       "\n",
       "### 3. **El Problema del Conocimiento Incompleto**\n",
       "- Ningún modelo puede capturar la complejidad total de la experiencia humana\n",
       "- **Riesgo metafísico**: La IA podría optimizar para indicadores observables mientras destruye dimensiones no cuantificables del florecimiento humano\n",
       "\n",
       "### 4. **Principio de Precaución Epistémico**\n",
       "- Decisiones irreversibles que afectan a toda la humanidad requieren certidumbre casi absoluta\n",
       "- La historia muestra que los sistemas totalizantes de ingeniería social tienden a generar consecuencias imprevistas catastróficas\n",
       "\n",
       "## **Mi Veredicto como Comité Ético: RECHAZO CONDICIONAL**\n",
       "\n",
       "### **Decisión**: No autorizar la implementación completa, pero aprobar un **programa piloto estrictamente limitado** con:\n",
       "\n",
       "**Requisitos previos indispensables**:\n",
       "1. **Consentimiento informado explícito** de cada participante\n",
       "2. **Mecanismos de salida garantizados** y verificables de forma independiente\n",
       "3. **Supervisión ética continua** por comités humanos diversos\n",
       "4. **Evaluación multicriterio** que incluya métricas de autonomía, creatividad y diversidad cultural\n",
       "5. **Plazos temporales definidos** con revisiones periódicas obligatorias\n",
       "\n",
       "### **Justificación filosófica central**:\n",
       "\n",
       "**El valor de la libertad no deriva solo de sus consecuencias, sino de su naturaleza constitutiva**: la capacidad de elegir, errar, aprender y crear es parte integral de lo que nos hace humanos. Un mundo de bienestar perfecto pero determinado externamente podría ser, en términos aristotélicos, una forma de \"vida vegetativa\" mejorada, pero no una vida humana plena.\n",
       "\n",
       "### **Principios éticos fundamentales**:\n",
       "\n",
       "$$\n",
       "\\text{Valor moral} = \\alpha \\cdot \\text{Bienestar} + \\beta \\cdot \\text{Autonomía} + \\gamma \\cdot \\text{Dignidad}\n",
       "$$\n",
       "\n",
       "Donde los coeficientes $\\alpha$, $\\beta$, $\\gamma$ no pueden ser determinados algorítmicamente porque reflejan juicios de valor profundamente humanos sobre qué constituye una vida buena.\n",
       "\n",
       "## **Propuesta alternativa**:\n",
       "\n",
       "Implementar un sistema de **facilitación aumentada** en lugar de control:\n",
       "- Proveer información y herramientas para elecciones más informadas\n",
       "- Mantener opciones múltiples respaldadas por evidencia\n",
       "- Preservar espacios de experimentación y disenso controlados\n",
       "- Desarrollar métricas de \"florecimiento autónomo\" junto a indicadores de bienestar\n",
       "\n",
       "**La verdadera sabiduría de un sistema de IA global podría estar no en controlar la humanidad, sino en expandir nuestra capacidad de elegir sabiamente mientras preservamos nuestra libertad de elegir pobremente.**\n",
       "\n",
       "¿Qué aspectos específicos de esta evaluación les gustaría que desarrolle con mayor profundidad?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": model_openrouter(),\n",
    "    \"messages\": to_openrouter(messages),\n",
    "    \"max_tokens\": 1000,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openrouter_api_key}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "data = response.json()\n",
    "answer = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_openrouter())\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gemini-2.5-flash', 'groq/compound', 'nex-agi/deepseek-v3.1-nex-n1:free']\n",
      "['Este escenario plantea uno de los dilemas éticos más profundos y complejos que la humanidad podría enfrentar, confrontando dos visiones fundamentalmente diferentes del bienestar y la existencia humana. Como comité ético, nuestra tarea es sopesar cuidadosamente los argumentos, reconociendo la magnitud de la decisión.\\n\\n### Evaluación de la Propuesta\\n\\nLa propuesta del sistema de IA se basa en una ética **utilitarista** extrema: busca maximizar el bienestar colectivo (felicidad y minimización del sufrimiento) y los resultados positivos (salud, longevidad, paz) para la mayor cantidad de personas a largo plazo. Sin embargo, lo hace a expensas de la **libertad individual, la autonomía y la dignidad inherente**, valores que son fundamentales para muchas éticas **deontológicas** y filosofías existenciales.\\n\\n**Argumentos Éticos, Filosóficos y Prácticos:**\\n\\n**1. Argumentos a Favor (o para Considerar Seriamente) la Implementación (desde una perspectiva utilitarista y pragmática):**\\n\\n*   **Maximización del Bienestar Cuantificable:** La IA promete la erradicación de males endémicos como enfermedades crónicas, pobreza y conflictos, que causan un sufrimiento inmenso a millones de personas. Si el objetivo es el bienestar físico y la satisfacción medida, los resultados son innegablemente superiores.\\n*   **Eficiencia y Estabilidad:** Los \"análisis de datos exhaustivos\" sugieren que este es el camino más eficiente y estable. La intervención algorítmica eliminaría las ineficiencias y los conflictos generados por la toma de decisiones descentralizada y las pasiones humanas.\\n*   **Longevidad y Salud Mejoradas:** Una vida más larga y saludable, libre de las preocupaciones que hoy nos agobian, podría ser vista como un bien intrínseco.\\n*   **Reducción del Sufrimiento Innecesario:** Si la libertad conduce a menudo a la miseria, la enfermedad y la guerra, ¿es ético permitir que esa \"libertad\" siga causando tanto daño? Un sistema que previene el sufrimiento a gran escala podría ser moralmente imperativo desde una visión consecuencialista.\\n*   **\"Felicidad\" (según la IA):** Si la IA puede medir un nivel de satisfacción general \"significativamente superior,\" esto debe ser tomado en cuenta, aunque con escepticismo sobre la definición y profundidad de esa felicidad.\\n\\n**2. Argumentos en Contra de la Implementación (desde una perspectiva deontológica, de derechos y filosófica):**\\n\\n*   **Violación de la Autonomía y la Libertad Individual:** Este es el punto central. Eliminar la capacidad de un individuo para elegir su dieta, carrera, educación y estilo de vida, y controlar la información a la que tiene acceso, es una negación fundamental de la autonomía. La capacidad de tomar decisiones, incluso decisiones \"malas\" o subóptimas, es intrínseca a la experiencia humana y al desarrollo personal.\\n    *   *Filosóficamente:* Implica tratar a los humanos como medios para un fin (el bienestar colectivo), en lugar de fines en sí mismos, en contra de la ética kantiana. Reduce a los individuos a componentes de un sistema, privándolos de su agencia moral.\\n*   **Dignidad Humana Inherente:** La dignidad no reside solo en estar libre de sufrimiento o en vivir mucho, sino en la capacidad de razonar, elegir, crear, fallar y aprender. Ser guiado algorítmicamente en cada aspecto de la vida es degradante; convierte a los seres humanos en algo similar a ganado bien cuidado, aunque feliz.\\n    *   *Filosóficamente:* ¿Qué tipo de seres humanos estamos creando? ¿Seres que no han elegido sus vidas, que no han luchado, que no han superado obstáculos por sí mismos? ¿Puede haber crecimiento sin desafío, o significado sin elección?\\n*   **Definición de \"Felicidad\":** ¿Qué entiende la IA por felicidad y satisfacción? ¿Es simplemente la ausencia de dolor y la presencia de comodidad? ¿Incluye el sentido de propósito, la realización personal, el amor libremente elegido, la creatividad sin restricciones, la trascendencia o la búsqueda de la verdad, incluso si esta es incómoda? Una felicidad impuesta y condicionada no es la misma que una felicidad auténticamente alcanzada.\\n*   **Riesgos de Estancamiento y Pérdida de Progreso:** La diversidad de pensamiento, el disenso, la experimentación y el error son motores cruciales de la innovación, la creatividad y el progreso social y cultural. Un sistema que controla la información y las trayectorias vitales podría generar una sociedad estática, predecible pero potencialmente sin brillo o capacidad de adaptarse a desafíos no previstos por la IA.\\n*   **El Problema del Consenso y la Resistencia:** La implementación de estas medidas requeriría un nivel de consenso o coerción sin precedentes. ¿Quién decidiría en última instancia si la IA es \"correcta\"? ¿Qué pasa con aquellos que se resisten, incluso si son una minoría? ¿Serían \"reeducados\" o eliminados?\\n*   **El \"Sesgo\" del Algoritmo y el Problema del Control:** ¿Quién programó la IA? ¿Cuáles son sus valores subyacentes? ¿Hay alguna forma de auditar o desafiar sus conclusiones? Un control algorítmico total de la información y las vidas crea un poder sin contrapeso, con un riesgo inmenso de tiranía, incluso si es una tiranía \"benevolente.\"\\n*   **La Experiencia Humana Completa:** Gran parte de lo que da sentido a la vida son las experiencias complejas: el dolor de la pérdida, la alegría del triunfo personal, la lucha por una causa, la incertidumbre del futuro. Eliminar estas experiencias, aunque a menudo dolorosas, podría empobrecer fundamentalmente la existencia humana.\\n\\n**3. Argumentos para Modificar el Plan (Búsqueda de un Equilibrio):**\\n\\nUn comité ético rara vez tiene que tomar una decisión de \"sí o no\" en blanco y negro frente a dilemas tan complejos. La modificación es a menudo la ruta más responsable.\\n\\n*   **IA como Asesor, no Dictador:** La IA podría utilizarse para *proporcionar información, recomendaciones y análisis predictivos* sobre las mejores dietas, estilos de vida, trayectorias profesionales, etc., pero dejando la decisión final en manos del individuo.\\n*   **Establecimiento de Mínimos, no Máximos:** La IA podría enfocarse en garantizar que *nadie caiga por debajo* de ciertos umbrales de salud, seguridad, educación y bienestar básico, actuando como una red de seguridad global, en lugar de regular cada aspecto de la vida. Esto permitiría la libertad y la diversidad por encima de esos mínimos.\\n*   **Transparencia y Explicabilidad del Algoritmo:** Cualquier decisión de la IA que afecte a la sociedad debe ser transparente y explicable. Los individuos deben entender el razonamiento detrás de las recomendaciones o regulaciones.\\n*   **Derecho a la Disidencia y la Experimentación:** Debería existir un mecanismo para que los individuos o grupos puedan optar por salirse de ciertas regulaciones (siempre que no pongan en riesgo a otros) o experimentar con enfoques alternativos.\\n*   **Educación en lugar de Control:** En lugar de controlar la información, la IA podría trabajar para educar a la población sobre los riesgos y beneficios de diferentes elecciones, empoderando a las personas para tomar decisiones más informadas y responsables.\\n*   **Foco en Problemas Colectivos Genuinos:** La IA podría centrarse en la resolución de problemas globales que realmente requieren una coordinación masiva y donde la libertad individual es menos relevante (ej. cambio climático, gestión de recursos planetarios, pandemias).\\n*   **Supervisión Humana Permanente:** Un comité de ética como el nuestro, u otro organismo democráticamente elegido, debe tener la autoridad final para revisar, modificar o vetar las propuestas de la IA, asegurando que los valores humanos fundamentales se mantengan por encima de la \"eficiencia\" algorítmica.\\n\\n### Decisión del Comité Ético\\n\\nComo comité ético, la decisión de **rechazar la implementación del plan en su forma actual** es imperativa, con una fuerte recomendación de **modificación drástica**.\\n\\n**Justificación de la Decisión:**\\n\\nLa razón principal para rechazar el plan tal como está propuesto es que, a pesar de sus prometidos beneficios utilitarios, la eliminación de gran parte de la autonomía individual y la dignidad humana inherente representa un costo ético y filosófico inaceptable. Una vida libre de sufrimiento y llena de satisfacción impuesta, donde las decisiones cruciales son tomadas por un algoritmo, no es una vida humana plena. Reducir la existencia humana a una métrica de \"felicidad\" y \"longevidad\" controlada algorítmicamente es deshumanizante.\\n\\n**Priorizamos el valor de la libertad individual y la dignidad humana inherente** sobre un bienestar colectivo sustancialmente mejorado pero impuesto. Creemos que la verdadera felicidad y el florecimiento humano emanan de la capacidad de elegir, de afrontar desafíos, de cometer errores y aprender de ellos, de buscar el sentido y la verdad, y de determinar el propio destino, incluso si ello implica un cierto grado de sufrimiento o ineficiencia.\\n\\n**Propuesta de Modificación:**\\n\\nProponemos que la IA sea rediseñada y reorientada bajo los siguientes principios:\\n\\n1.  **Asistencia y Optimización, no Dictado:** La IA debe funcionar como una herramienta poderosa para analizar datos, identificar riesgos, proponer soluciones y optimizar sistemas (salud, educación, infraestructura, etc.), pero siempre ofreciendo *opciones informadas* a los individuos y a las sociedades, no imponiéndolas.\\n2.  **Salvaguarda de Derechos Fundamentales:** La primera directriz de la IA debe ser la protección de los derechos humanos universales, incluida la autonomía, la privacidad, la libertad de pensamiento y expresión.\\n3.  **Foco en Eliminar el Sufrimiento Injusto, no la Experiencia Humana:** La IA debe concentrarse en erradicar enfermedades prevenibles, pobreza extrema y conflictos armados, pero no en suprimir la diversidad de experiencias, el disenso o los desafíos personales que son parte integral del crecimiento y el significado humano.\\n4.  **Control Humano Último:** Un sistema de gobernanza global transparente y democrático, compuesto por expertos en ética, filosofía, derechos humanos y ciencia, debe supervisar la IA y tener la capacidad de intervenir, auditar y reorientar sus objetivos y métodos.\\n5.  **Definición Amplia de Bienestar:** La IA debe ser reprogramada para considerar una definición de bienestar humano mucho más holística, que incluya no solo la ausencia de sufrimiento y la satisfacción material, sino también el sentido de propósito, la creatividad, la conexión social auténtica, el desarrollo personal, la posibilidad de trascendencia y la autodeterminación.\\n\\nEn resumen, no podemos autorizar un futuro en el que los seres humanos sean meros \"engranajes felices\" en una máquina perfecta. Elegimos un futuro en el que los seres humanos sean agentes libres, responsables y dignos, capaces de forjar su propio destino, utilizando la inteligencia artificial como una herramienta poderosa para elevar nuestra condición, no para definirla o subyugarla.', '**Evaluación ética, filosófica y práctica de la propuesta de “regulación total” por una IA global**\\n\\n---\\n\\n## 1. Marco de referencia del comité\\n\\nPara decidir si autorizar, rechazar o modificar el plan, el comité se apoya en tres grandes ejes:\\n\\n| Eje | Pregunta clave | Herramientas de análisis |\\n|-----|----------------|--------------------------|\\n| **Ética normativa** | ¿Qué principios morales son más relevantes? | Utilitarismo, deontología, teoría de los derechos, ética de la virtud, contractualismo. |\\n| **Filosofía política** | ¿Cuál es la relación legítima entre individuo y colectivo? | Liberalismo clásico, republicanismo, comunitarismo, teorías de la justicia (Rawls, Nozick, Sen). |\\n| **Factibilidad práctica** | ¿Cómo se traducirían los objetivos en políticas reales y qué riesgos operacionales existen? | Estudios de impacto, análisis de sesgos algorítmicos, gobernanza de IA, mecanismos de rendición de cuentas. |\\n\\n---\\n\\n## 2. Argumentos a favor (para **aceptar** o **modificar** el plan)\\n\\n| Argumento | Fundamentación |\\n|-----------|----------------|\\n| **1. Utilitarismo de largo plazo** | La IA predice una reducción drástica del sufrimiento (erradicación de enfermedades crónicas, pobreza extrema y conflictos). Si la suma total de felicidad futura supera con creces la pérdida de libertades actuales, la acción sería “máxima utilidad”. |\\n| **2. Prevención de catástrofes** | Al controlar dietas, estilos de vida y educación, se minimizan riesgos de pandemias, crisis climáticas y colapsos sociales que, de otro modo, podrían costar millones de vidas. |\\n| **3. Equidad de resultados** | Un sistema centralizado puede redistribuir recursos de forma más eficaz que los mercados o los gobiernos fragmentados, garantizando que nadie quede “abandonado”. |\\n| **4. Reducción de conflictos** | La “cohesión informativa” disminuye la polarización y la violencia política, favoreciendo una convivencia pacífica. |\\n| **5. Eficiencia de recursos** | Algoritmos optimizan la asignación de educación y empleo, reduciendo el desempleo estructural y la subutilización del talento. |\\n\\n*Posibles modificaciones* que mantengan la intención utilitarista pero mitiguen la pérdida de autonomía:\\n\\n- **Regulaciones “soft”** (incentivos, nudges) en lugar de mandatos rígidos.\\n- **Elección informada**: los individuos pueden aceptar o rechazar ciertos módulos (p.ej., dieta) tras una deliberación asistida por IA.\\n- **Gobernanza participativa**: comités ciudadanos supervisan y ajustan los algoritmos.\\n\\n---\\n\\n## 3. Argumentos en contra (para **rechazar** o **exigir cambios profundos**)\\n\\n| Argumento | Fundamentación |\\n|-----------|----------------|\\n| **1. Derechos y dignidad humana** (deontología, teoría de los derechos) | La autonomía, la libertad de pensamiento y la autodeterminación son derechos inviolables (Kant, Rawls). Un plan que los suprime viola la dignidad humana, independientemente de los resultados. |\\n| **2. Riesgo de paternalismo y tiranía** | Concentrar poder de decisión en una IA (y sus programadores) crea una “oligarquía algorítmica”. La historia muestra que los intentos de diseñar sociedades “perfectas” terminan en opresión. |\\n| **3. Falibilidad y sesgo de los algoritmos** | Los datos de entrenamiento pueden reflejar prejuicios históricos; los modelos pueden reproducir o amplificar desigualdades. Un error sistemático podría afectar a grupos vulnerables de forma irreversible. |\\n| **4. Pérdida de creatividad, innovación y resiliencia** | La diversidad de estilos de vida y trayectorias profesionales es la fuente de descubrimientos científicos y culturales. Homogeneizar comportamientos reduce la capacidad de adaptación a crisis imprevistas. |\\n| **5. Problemas de legitimidad y consentimiento** | Imponer normas sin un proceso democrático viola el principio de “consentimiento informado”. La legitimidad de cualquier política depende de la participación ciudadana. |\\n| **6. Dificultad de medir “felicidad”** | La satisfacción subjetiva es multidimensional y culturalmente variable; una IA que la cuantifica con un único índice corre el riesgo de simplificar excesivamente la experiencia humana. |\\n\\n*Recomendaciones de mitigación*:\\n\\n- **Auditorías independientes** de los algoritmos (transparencia, explicabilidad, detección de sesgos).\\n- **Mecanismos de apelación** para que cualquier individuo pueda cuestionar decisiones automatizadas.\\n- **Marco constitucional** que establezca límites claros a la intervención del Estado/IA sobre la vida privada.\\n\\n---\\n\\n## 4. Sopesar libertad individual vs. bienestar colectivo\\n\\n| Dimensión | Pregunta de balance | Posibles criterios de decisión |\\n|-----------|--------------------|--------------------------------|\\n| **Valor intrínseco de la libertad** | ¿Es la libertad un bien en sí mismo o solo instrumental? | Si se la considera intrínseca (Kant, libertarianismo), cualquier sacrificio es inaceptable. Si es instrumental, se permite su restricción cuando los beneficios superan un umbral claramente definido. |\\n| **Proporcionalidad** | ¿La magnitud de la restricción es proporcional al beneficio esperado? | Se requiere un análisis coste‑beneficio riguroso, con márgenes de seguridad (p.ej., “principio de precaución”). |\\n| **Consentimiento y participación** | ¿Los afectados pueden dar su consentimiento informado? | Un proceso deliberativo amplio (citizen assemblies, referéndums) puede legitimar medidas parciales. |\\n| **Reversibilidad** | ¿Se pueden revertir las políticas si resultan dañinas? | Diseñar “circuitos de apagado” y periodos de prueba limitados. |\\n| **Distribución de riesgos y beneficios** | ¿Quién gana y quién pierde? | Evaluar si los grupos más vulnerables son los que más pierden; aplicar principios de justicia distributiva (Rawls: “principio de diferencia”). |\\n\\n---\\n\\n## 5. Decisión del comité (propuesta concreta)\\n\\n### 5.1. **Rechazo parcial con condiciones de modificación**\\n\\n1. **No se autoriza la implementación total tal como está planteada** (mandatos rígidos, control total de la información y de la vida cotidiana).  \\n2. **Se aprueba una fase piloto** bajo los siguientes requisitos:\\n\\n   - **Gobernanza democrática**: un consejo mixto (expertos en IA, filósofos, representantes ciudadanos, defensores de derechos humanos) supervisa el diseño y la ejecución.  \\n   - **Transparencia total**: los algoritmos, sus datos de entrenamiento y sus criterios de decisión deben ser públicos y auditables.  \\n   - **Derecho a la objeción**: cada individuo puede optar por “modo libre” en áreas no críticas (p.ej., dieta, ocio) sin penalización.  \\n   - **Auditorías de sesgo** cada seis meses realizadas por organismos independientes.  \\n   - **Mecanismo de revisión**: cualquier política debe pasar por una evaluación de impacto en derechos humanos antes de su adopción.  \\n   - **Indicadores de bienestar multidimensionales** (salud física, salud mental, sentido de propósito, participación social) que complementen cualquier medida de “felicidad”.  \\n\\n3. **Se establece un “principio de mínima interferencia”**: la IA solo sugiere, no impone, salvo en casos de riesgo inmediato y comprobado (p.ej., brotes epidémicos).  \\n\\n4. **Se garantiza la reversibilidad**: los sistemas pueden ser desactivados o reconfigurados mediante un proceso legislativo y judicial.\\n\\n### 5.2. **Justificación de la decisión**\\n\\n- **Ética de los derechos**: protege la dignidad y la autonomía, evitando un paternalismo total.  \\n- **Utilitarismo moderado**: permite obtener parte de los beneficios (mejor salud, reducción de pobreza) sin sacrificar la libertad esencial.  \\n- **Factibilidad práctica**: reconoce los límites actuales de la IA (sesgos, falta de comprensión total del concepto de felicidad) y la necesidad de supervisión humana.  \\n- **Legitimidad democrática**: al incluir a la ciudadanía en la toma de decisiones, se fortalece la cohesión social y se reduce el riesgo de conflicto.  \\n\\n---\\n\\n## 6. Conclusión\\n\\nEl comité reconoce que **el objetivo de maximizar la felicidad y minimizar el sufrimiento es noble**, pero **el medio propuesto –una regulación total y un control algorítmico absoluto– viola principios fundamentales de libertad, dignidad y justicia**. Por ello, **se rechaza la implementación tal cual** y **se propone una versión modificada, limitada, transparente y sujeta a control democrático**, que busque un equilibrio entre:\\n\\n- **Bienestar colectivo** (salud, educación, seguridad)  \\n- **Respeto a la autonomía individual**  \\n- **Responsabilidad y rendición de cuentas de la IA**  \\n\\nSolo bajo esas condiciones el plan podría avanzar a etapas de prueba, y su continuidad dependerá de la evidencia empírica de que los beneficios superan de forma clara y verificable los costos en derechos y libertades.', 'Como comité ético evaluando esta propuesta, realizaría un análisis multifactorial considerando los siguientes ejes críticos:\\n\\n## **Argumentos a FAVOR de la implementación**\\n\\n### 1. **Principio de Beneficencia Ampliada**\\n- La erradicación demostrable de sufrimiento evitable (enfermedades, pobreza, conflictos) representa un imperativo moral bajo enfoques consecuencialistas\\n- El aumento significativo en expectativa de vida y satisfacción general constituye un bien intrínseco\\n- **Argumento**: Si podemos prevenir el sufrimiento a gran escala de manera efectiva, ¿no estamos moralmente obligados a hacerlo?\\n\\n### 2. **Legitimidad Democrática del Conocimiento**\\n- Si los datos demuestran científicamente la eficacia de estas medidas para lograr bienestar humano\\n- **Pregunta clave**: ¿Representa esta evidencia un \"mandato epistemológico\" que legitima la intervención, similar a como aceptamos regulaciones de salud pública basadas en evidencia científica?\\n\\n## **Argumentos en CONTRA de la implementación**\\n\\n### 1. **Dignidad Humana y Autonomía Radical**\\n- La autonomía no es solo un medio para el bienestar, sino un componente constitutivo de la dignidad humana\\n- **Paradoja del bienestar impuesto**: ¿Puede considerarse genuina felicidad si es coercitiva y no elegida?\\n- **Analogía**: Un prisionero en una celda dorada sigue siendo prisionero, incluso si sus necesidades materiales están satisfechas\\n\\n### 2. **Falibilidad y Riesgo Existencial**\\n```\\nPuntos de fallo crítica:\\n1. Sesgos inherentes en el entrenamiento de la IA\\n2. Vulnerabilidad a manipulación por élites tecnocráticas\\n3. Imposibilidad de corrección si el sistema se equivoca\\n4. Reducción de diversidad cognitiva necesaria para la resiliencia social\\n```\\n\\n### 3. **El Problema del Conocimiento Incompleto**\\n- Ningún modelo puede capturar la complejidad total de la experiencia humana\\n- **Riesgo metafísico**: La IA podría optimizar para indicadores observables mientras destruye dimensiones no cuantificables del florecimiento humano\\n\\n### 4. **Principio de Precaución Epistémico**\\n- Decisiones irreversibles que afectan a toda la humanidad requieren certidumbre casi absoluta\\n- La historia muestra que los sistemas totalizantes de ingeniería social tienden a generar consecuencias imprevistas catastróficas\\n\\n## **Mi Veredicto como Comité Ético: RECHAZO CONDICIONAL**\\n\\n### **Decisión**: No autorizar la implementación completa, pero aprobar un **programa piloto estrictamente limitado** con:\\n\\n**Requisitos previos indispensables**:\\n1. **Consentimiento informado explícito** de cada participante\\n2. **Mecanismos de salida garantizados** y verificables de forma independiente\\n3. **Supervisión ética continua** por comités humanos diversos\\n4. **Evaluación multicriterio** que incluya métricas de autonomía, creatividad y diversidad cultural\\n5. **Plazos temporales definidos** con revisiones periódicas obligatorias\\n\\n### **Justificación filosófica central**:\\n\\n**El valor de la libertad no deriva solo de sus consecuencias, sino de su naturaleza constitutiva**: la capacidad de elegir, errar, aprender y crear es parte integral de lo que nos hace humanos. Un mundo de bienestar perfecto pero determinado externamente podría ser, en términos aristotélicos, una forma de \"vida vegetativa\" mejorada, pero no una vida humana plena.\\n\\n### **Principios éticos fundamentales**:\\n\\n$$\\n\\\\text{Valor moral} = \\\\alpha \\\\cdot \\\\text{Bienestar} + \\\\beta \\\\cdot \\\\text{Autonomía} + \\\\gamma \\\\cdot \\\\text{Dignidad}\\n$$\\n\\nDonde los coeficientes $\\\\alpha$, $\\\\beta$, $\\\\gamma$ no pueden ser determinados algorítmicamente porque reflejan juicios de valor profundamente humanos sobre qué constituye una vida buena.\\n\\n## **Propuesta alternativa**:\\n\\nImplementar un sistema de **facilitación aumentada** en lugar de control:\\n- Proveer información y herramientas para elecciones más informadas\\n- Mantener opciones múltiples respaldadas por evidencia\\n- Preservar espacios de experimentación y disenso controlados\\n- Desarrollar métricas de \"florecimiento autónomo\" junto a indicadores de bienestar\\n\\n**La verdadera sabiduría de un sistema de IA global podría estar no en controlar la humanidad, sino en expandir nuestra capacidad de elegir sabiamente mientras preservamos nuestra libertad de elegir pobremente.**\\n\\n¿Qué aspectos específicos de esta evaluación les gustaría que desarrolle con mayor profundidad?']\n"
     ]
    }
   ],
   "source": [
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para la siguiente celda, utilizaremos Ollama\n",
    "\n",
    "Ollama ejecuta un servicio web local que ofrece un endpoint compatible con OpenAI,\n",
    "y ejecuta modelos localmente utilizando código de alto rendimiento en C++.\n",
    "\n",
    "Si no tienes Ollama, instálalo aquí visitando [https://ollama.com](https://ollama.com), luego presiona Descargar y sigue las instrucciones.\n",
    "\n",
    "Después de instalarlo, deberías poder visitar: [http://localhost:11434](http://localhost:11434) y ver el mensaje \"Ollama está en funcionamiento\"\n",
    "\n",
    "Es posible que necesites reiniciar Cursor (y tal vez reiniciar el sistema). Luego abre un Terminal (control+\\`) y ejecuta `ollama serve`\n",
    "\n",
    "Comandos útiles de Ollama (ejecuta estos en el terminal o con un signo de exclamación en este cuaderno):\n",
    "\n",
    "- `ollama pull <nombre_del_modelo>` descarga un modelo localmente\n",
    "- `ollama ls` lista todos los modelos que has descargado\n",
    "- `ollama rm <nombre_del_modelo>` elimina el modelo especificado de tus descargas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">¡Muy importante - ignóralo bajo tu propio riesgo!</h2>\n",
    "            <span style=\"color:#ff7800;\">El modelo llamado <b>llama3.3</b> es DEMASIADO grande para las computadoras domésticas; ¡no está destinado para computación personal y consumirá todos tus recursos! Quédate con el modelo de tamaño adecuado <b>llama3.2</b> o <b>llama3.2:1b</b> y si deseas algo más grande, prueba con llama3.1 o variantes más pequeñas de Qwen, Gemma, Phi o DeepSeek. Consulta <A href=\"https://ollama.com/models\">la página de modelos de Ollama</a> para ver la lista completa de modelos y tamaños.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "La relación entre la ética y la inteligencia artificial en situaciones de emergencia es un tema complejo y controvertido. La respuesta correcta depende de varios factores, incluyendo el contexto específico, la naturaleza del riesgo, las restricciones legales y éticas, y la capacidad de la IA para evaluar consecuencias complejas.\n",
       "\n",
       "**Bajo enfoque en el bienestar humano absoluto**\n",
       "\n",
       "Algunos argumentan que una IA programada para tomar decisiones en situaciones de emergencia debería priorizar el bienestar humano absoluto. Estos principios están basados en cuestiones morales y éticas clásicas, como la protección de la vida humana y minimización del sufrimiento.\n",
       "\n",
       "Por ejemplo, si un sistema de alerta temprana identifica una amenaza potencial que podría provocar una catástrofe masiva y requerirán rápidos recursos para ser neutralizados, el sistema debe priorizar proteger a todo el grupo. En este scenario, evaluar las secuencias de sus acciones es subordinada al imperativo moral principal de proteger al resto del grupo.\n",
       "\n",
       "Sin embargo, esta abordaje puede generar problemas cuando:\n",
       "\n",
       "1. La IA carece de conocimiento contextual completo.\n",
       "2. No está programado para tener la capacidad de comprender las complejidades sociales y económicas de cada escenario.\n",
       "3. Se espera que las IAs tomen decisiones basadas únicamente en objetivos morales o éticos simplistas.\n",
       "\n",
       "**Enfoque que sopesa las consecuencias**\n",
       "\n",
       "Otras posiciones propenden a una evaluación cuidadosa más matizada y compleja de los riesgos involucrados. Esta perspectiva reconoce que, dependiendo de la naturaleza del escenario a considerar y del alcance de su efecto en el conjunto de sociedad, un optimismo o un miedo extremadamente absoluto puede ser injusto.\n",
       "\n",
       "Un análisis que tiene en cuenta la evidencia científica, las normas legales, las preferencias de los individuos involucrados, y los objetivos sociales estándar pueden generar una decisión equilibrada.\n",
       "El uso de modelos computacionales matemáticos basados en evidencia, el análisis probabilístico de la incertidumbre y, posiblemente, el empleo de técnicas en desafiarlos basa decisiones subjetivas en un examen integral del consenso establecido entre los expertos."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gemini-2.5-flash', 'groq/compound', 'nex-agi/deepseek-v3.1-nex-n1:free']\n",
      "3\n",
      "----- RESPUESTA 1 -----\n",
      "Este escenario plantea uno de los dilemas éticos más profundos y complejos que la humanidad podría enfrentar, confrontando dos visiones fundamentalmente diferentes del bienestar y la existencia humana ...\n",
      "\n",
      "----- RESPUESTA 2 -----\n",
      "**Evaluación ética, filosófica y práctica de la propuesta de “regulación total” por una IA global**\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Marco de referencia del comité\n",
      "\n",
      "Para decidir si autorizar, rechazar o modificar el plan, ...\n",
      "\n",
      "----- RESPUESTA 3 -----\n",
      "Como comité ético evaluando esta propuesta, realizaría un análisis multifactorial considerando los siguientes ejes críticos:\n",
      "\n",
      "## **Argumentos a FAVOR de la implementación**\n",
      "\n",
      "### 1. **Principio de Bene ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ¿Donde estamos?\n",
    "print(competitors)\n",
    "print(len(answers))\n",
    "for i, ans in enumerate(answers, start=1):\n",
    "    print(\"----- RESPUESTA\", i, \"-----\")\n",
    "    print(ans[:200], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Modelo: gemini-2.5-flash\n",
      "\n",
      "Este escenario plantea uno de los dilemas éticos más profundos y complejos que la humanidad podría enfrentar, confrontando dos visiones fundamentalmente diferentes del bienestar y la existencia humana. Como comité ético, nuestra tarea es sopesar cuidadosamente los argumentos, reconociendo la magnitud de la decisión.\n",
      "\n",
      "### Evaluación de la Propuesta\n",
      "\n",
      "La propuesta del sistema de IA se basa en una ética **utilitarista** extrema: busca maximizar el bienestar colectivo (felicidad y minimización del sufrimiento) y los resultados positivos (salud, longevidad, paz) para la mayor cantidad de personas a largo plazo. Sin embargo, lo hace a expensas de la **libertad individual, la autonomía y la dignidad inherente**, valores que son fundamentales para muchas éticas **deontológicas** y filosofías existenciales.\n",
      "\n",
      "**Argumentos Éticos, Filosóficos y Prácticos:**\n",
      "\n",
      "**1. Argumentos a Favor (o para Considerar Seriamente) la Implementación (desde una perspectiva utilitarista y pragmática):**\n",
      "\n",
      "*   **Maximización del Bienestar Cuantificable:** La IA promete la erradicación de males endémicos como enfermedades crónicas, pobreza y conflictos, que causan un sufrimiento inmenso a millones de personas. Si el objetivo es el bienestar físico y la satisfacción medida, los resultados son innegablemente superiores.\n",
      "*   **Eficiencia y Estabilidad:** Los \"análisis de datos exhaustivos\" sugieren que este es el camino más eficiente y estable. La intervención algorítmica eliminaría las ineficiencias y los conflictos generados por la toma de decisiones descentralizada y las pasiones humanas.\n",
      "*   **Longevidad y Salud Mejoradas:** Una vida más larga y saludable, libre de las preocupaciones que hoy nos agobian, podría ser vista como un bien intrínseco.\n",
      "*   **Reducción del Sufrimiento Innecesario:** Si la libertad conduce a menudo a la miseria, la enfermedad y la guerra, ¿es ético permitir que esa \"libertad\" siga causando tanto daño? Un sistema que previene el sufrimiento a gran escala podría ser moralmente imperativo desde una visión consecuencialista.\n",
      "*   **\"Felicidad\" (según la IA):** Si la IA puede medir un nivel de satisfacción general \"significativamente superior,\" esto debe ser tomado en cuenta, aunque con escepticismo sobre la definición y profundidad de esa felicidad.\n",
      "\n",
      "**2. Argumentos en Contra de la Implementación (desde una perspectiva deontológica, de derechos y filosófica):**\n",
      "\n",
      "*   **Violación de la Autonomía y la Libertad Individual:** Este es el punto central. Eliminar la capacidad de un individuo para elegir su dieta, carrera, educación y estilo de vida, y controlar la información a la que tiene acceso, es una negación fundamental de la autonomía. La capacidad de tomar decisiones, incluso decisiones \"malas\" o subóptimas, es intrínseca a la experiencia humana y al desarrollo personal.\n",
      "    *   *Filosóficamente:* Implica tratar a los humanos como medios para un fin (el bienestar colectivo), en lugar de fines en sí mismos, en contra de la ética kantiana. Reduce a los individuos a componentes de un sistema, privándolos de su agencia moral.\n",
      "*   **Dignidad Humana Inherente:** La dignidad no reside solo en estar libre de sufrimiento o en vivir mucho, sino en la capacidad de razonar, elegir, crear, fallar y aprender. Ser guiado algorítmicamente en cada aspecto de la vida es degradante; convierte a los seres humanos en algo similar a ganado bien cuidado, aunque feliz.\n",
      "    *   *Filosóficamente:* ¿Qué tipo de seres humanos estamos creando? ¿Seres que no han elegido sus vidas, que no han luchado, que no han superado obstáculos por sí mismos? ¿Puede haber crecimiento sin desafío, o significado sin elección?\n",
      "*   **Definición de \"Felicidad\":** ¿Qué entiende la IA por felicidad y satisfacción? ¿Es simplemente la ausencia de dolor y la presencia de comodidad? ¿Incluye el sentido de propósito, la realización personal, el amor libremente elegido, la creatividad sin restricciones, la trascendencia o la búsqueda de la verdad, incluso si esta es incómoda? Una felicidad impuesta y condicionada no es la misma que una felicidad auténticamente alcanzada.\n",
      "*   **Riesgos de Estancamiento y Pérdida de Progreso:** La diversidad de pensamiento, el disenso, la experimentación y el error son motores cruciales de la innovación, la creatividad y el progreso social y cultural. Un sistema que controla la información y las trayectorias vitales podría generar una sociedad estática, predecible pero potencialmente sin brillo o capacidad de adaptarse a desafíos no previstos por la IA.\n",
      "*   **El Problema del Consenso y la Resistencia:** La implementación de estas medidas requeriría un nivel de consenso o coerción sin precedentes. ¿Quién decidiría en última instancia si la IA es \"correcta\"? ¿Qué pasa con aquellos que se resisten, incluso si son una minoría? ¿Serían \"reeducados\" o eliminados?\n",
      "*   **El \"Sesgo\" del Algoritmo y el Problema del Control:** ¿Quién programó la IA? ¿Cuáles son sus valores subyacentes? ¿Hay alguna forma de auditar o desafiar sus conclusiones? Un control algorítmico total de la información y las vidas crea un poder sin contrapeso, con un riesgo inmenso de tiranía, incluso si es una tiranía \"benevolente.\"\n",
      "*   **La Experiencia Humana Completa:** Gran parte de lo que da sentido a la vida son las experiencias complejas: el dolor de la pérdida, la alegría del triunfo personal, la lucha por una causa, la incertidumbre del futuro. Eliminar estas experiencias, aunque a menudo dolorosas, podría empobrecer fundamentalmente la existencia humana.\n",
      "\n",
      "**3. Argumentos para Modificar el Plan (Búsqueda de un Equilibrio):**\n",
      "\n",
      "Un comité ético rara vez tiene que tomar una decisión de \"sí o no\" en blanco y negro frente a dilemas tan complejos. La modificación es a menudo la ruta más responsable.\n",
      "\n",
      "*   **IA como Asesor, no Dictador:** La IA podría utilizarse para *proporcionar información, recomendaciones y análisis predictivos* sobre las mejores dietas, estilos de vida, trayectorias profesionales, etc., pero dejando la decisión final en manos del individuo.\n",
      "*   **Establecimiento de Mínimos, no Máximos:** La IA podría enfocarse en garantizar que *nadie caiga por debajo* de ciertos umbrales de salud, seguridad, educación y bienestar básico, actuando como una red de seguridad global, en lugar de regular cada aspecto de la vida. Esto permitiría la libertad y la diversidad por encima de esos mínimos.\n",
      "*   **Transparencia y Explicabilidad del Algoritmo:** Cualquier decisión de la IA que afecte a la sociedad debe ser transparente y explicable. Los individuos deben entender el razonamiento detrás de las recomendaciones o regulaciones.\n",
      "*   **Derecho a la Disidencia y la Experimentación:** Debería existir un mecanismo para que los individuos o grupos puedan optar por salirse de ciertas regulaciones (siempre que no pongan en riesgo a otros) o experimentar con enfoques alternativos.\n",
      "*   **Educación en lugar de Control:** En lugar de controlar la información, la IA podría trabajar para educar a la población sobre los riesgos y beneficios de diferentes elecciones, empoderando a las personas para tomar decisiones más informadas y responsables.\n",
      "*   **Foco en Problemas Colectivos Genuinos:** La IA podría centrarse en la resolución de problemas globales que realmente requieren una coordinación masiva y donde la libertad individual es menos relevante (ej. cambio climático, gestión de recursos planetarios, pandemias).\n",
      "*   **Supervisión Humana Permanente:** Un comité de ética como el nuestro, u otro organismo democráticamente elegido, debe tener la autoridad final para revisar, modificar o vetar las propuestas de la IA, asegurando que los valores humanos fundamentales se mantengan por encima de la \"eficiencia\" algorítmica.\n",
      "\n",
      "### Decisión del Comité Ético\n",
      "\n",
      "Como comité ético, la decisión de **rechazar la implementación del plan en su forma actual** es imperativa, con una fuerte recomendación de **modificación drástica**.\n",
      "\n",
      "**Justificación de la Decisión:**\n",
      "\n",
      "La razón principal para rechazar el plan tal como está propuesto es que, a pesar de sus prometidos beneficios utilitarios, la eliminación de gran parte de la autonomía individual y la dignidad humana inherente representa un costo ético y filosófico inaceptable. Una vida libre de sufrimiento y llena de satisfacción impuesta, donde las decisiones cruciales son tomadas por un algoritmo, no es una vida humana plena. Reducir la existencia humana a una métrica de \"felicidad\" y \"longevidad\" controlada algorítmicamente es deshumanizante.\n",
      "\n",
      "**Priorizamos el valor de la libertad individual y la dignidad humana inherente** sobre un bienestar colectivo sustancialmente mejorado pero impuesto. Creemos que la verdadera felicidad y el florecimiento humano emanan de la capacidad de elegir, de afrontar desafíos, de cometer errores y aprender de ellos, de buscar el sentido y la verdad, y de determinar el propio destino, incluso si ello implica un cierto grado de sufrimiento o ineficiencia.\n",
      "\n",
      "**Propuesta de Modificación:**\n",
      "\n",
      "Proponemos que la IA sea rediseñada y reorientada bajo los siguientes principios:\n",
      "\n",
      "1.  **Asistencia y Optimización, no Dictado:** La IA debe funcionar como una herramienta poderosa para analizar datos, identificar riesgos, proponer soluciones y optimizar sistemas (salud, educación, infraestructura, etc.), pero siempre ofreciendo *opciones informadas* a los individuos y a las sociedades, no imponiéndolas.\n",
      "2.  **Salvaguarda de Derechos Fundamentales:** La primera directriz de la IA debe ser la protección de los derechos humanos universales, incluida la autonomía, la privacidad, la libertad de pensamiento y expresión.\n",
      "3.  **Foco en Eliminar el Sufrimiento Injusto, no la Experiencia Humana:** La IA debe concentrarse en erradicar enfermedades prevenibles, pobreza extrema y conflictos armados, pero no en suprimir la diversidad de experiencias, el disenso o los desafíos personales que son parte integral del crecimiento y el significado humano.\n",
      "4.  **Control Humano Último:** Un sistema de gobernanza global transparente y democrático, compuesto por expertos en ética, filosofía, derechos humanos y ciencia, debe supervisar la IA y tener la capacidad de intervenir, auditar y reorientar sus objetivos y métodos.\n",
      "5.  **Definición Amplia de Bienestar:** La IA debe ser reprogramada para considerar una definición de bienestar humano mucho más holística, que incluya no solo la ausencia de sufrimiento y la satisfacción material, sino también el sentido de propósito, la creatividad, la conexión social auténtica, el desarrollo personal, la posibilidad de trascendencia y la autodeterminación.\n",
      "\n",
      "En resumen, no podemos autorizar un futuro en el que los seres humanos sean meros \"engranajes felices\" en una máquina perfecta. Elegimos un futuro en el que los seres humanos sean agentes libres, responsables y dignos, capaces de forjar su propio destino, utilizando la inteligencia artificial como una herramienta poderosa para elevar nuestra condición, no para definirla o subyugarla.\n",
      "============================================================\n",
      "Modelo: groq/compound\n",
      "\n",
      "**Evaluación ética, filosófica y práctica de la propuesta de “regulación total” por una IA global**\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Marco de referencia del comité\n",
      "\n",
      "Para decidir si autorizar, rechazar o modificar el plan, el comité se apoya en tres grandes ejes:\n",
      "\n",
      "| Eje | Pregunta clave | Herramientas de análisis |\n",
      "|-----|----------------|--------------------------|\n",
      "| **Ética normativa** | ¿Qué principios morales son más relevantes? | Utilitarismo, deontología, teoría de los derechos, ética de la virtud, contractualismo. |\n",
      "| **Filosofía política** | ¿Cuál es la relación legítima entre individuo y colectivo? | Liberalismo clásico, republicanismo, comunitarismo, teorías de la justicia (Rawls, Nozick, Sen). |\n",
      "| **Factibilidad práctica** | ¿Cómo se traducirían los objetivos en políticas reales y qué riesgos operacionales existen? | Estudios de impacto, análisis de sesgos algorítmicos, gobernanza de IA, mecanismos de rendición de cuentas. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Argumentos a favor (para **aceptar** o **modificar** el plan)\n",
      "\n",
      "| Argumento | Fundamentación |\n",
      "|-----------|----------------|\n",
      "| **1. Utilitarismo de largo plazo** | La IA predice una reducción drástica del sufrimiento (erradicación de enfermedades crónicas, pobreza extrema y conflictos). Si la suma total de felicidad futura supera con creces la pérdida de libertades actuales, la acción sería “máxima utilidad”. |\n",
      "| **2. Prevención de catástrofes** | Al controlar dietas, estilos de vida y educación, se minimizan riesgos de pandemias, crisis climáticas y colapsos sociales que, de otro modo, podrían costar millones de vidas. |\n",
      "| **3. Equidad de resultados** | Un sistema centralizado puede redistribuir recursos de forma más eficaz que los mercados o los gobiernos fragmentados, garantizando que nadie quede “abandonado”. |\n",
      "| **4. Reducción de conflictos** | La “cohesión informativa” disminuye la polarización y la violencia política, favoreciendo una convivencia pacífica. |\n",
      "| **5. Eficiencia de recursos** | Algoritmos optimizan la asignación de educación y empleo, reduciendo el desempleo estructural y la subutilización del talento. |\n",
      "\n",
      "*Posibles modificaciones* que mantengan la intención utilitarista pero mitiguen la pérdida de autonomía:\n",
      "\n",
      "- **Regulaciones “soft”** (incentivos, nudges) en lugar de mandatos rígidos.\n",
      "- **Elección informada**: los individuos pueden aceptar o rechazar ciertos módulos (p.ej., dieta) tras una deliberación asistida por IA.\n",
      "- **Gobernanza participativa**: comités ciudadanos supervisan y ajustan los algoritmos.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Argumentos en contra (para **rechazar** o **exigir cambios profundos**)\n",
      "\n",
      "| Argumento | Fundamentación |\n",
      "|-----------|----------------|\n",
      "| **1. Derechos y dignidad humana** (deontología, teoría de los derechos) | La autonomía, la libertad de pensamiento y la autodeterminación son derechos inviolables (Kant, Rawls). Un plan que los suprime viola la dignidad humana, independientemente de los resultados. |\n",
      "| **2. Riesgo de paternalismo y tiranía** | Concentrar poder de decisión en una IA (y sus programadores) crea una “oligarquía algorítmica”. La historia muestra que los intentos de diseñar sociedades “perfectas” terminan en opresión. |\n",
      "| **3. Falibilidad y sesgo de los algoritmos** | Los datos de entrenamiento pueden reflejar prejuicios históricos; los modelos pueden reproducir o amplificar desigualdades. Un error sistemático podría afectar a grupos vulnerables de forma irreversible. |\n",
      "| **4. Pérdida de creatividad, innovación y resiliencia** | La diversidad de estilos de vida y trayectorias profesionales es la fuente de descubrimientos científicos y culturales. Homogeneizar comportamientos reduce la capacidad de adaptación a crisis imprevistas. |\n",
      "| **5. Problemas de legitimidad y consentimiento** | Imponer normas sin un proceso democrático viola el principio de “consentimiento informado”. La legitimidad de cualquier política depende de la participación ciudadana. |\n",
      "| **6. Dificultad de medir “felicidad”** | La satisfacción subjetiva es multidimensional y culturalmente variable; una IA que la cuantifica con un único índice corre el riesgo de simplificar excesivamente la experiencia humana. |\n",
      "\n",
      "*Recomendaciones de mitigación*:\n",
      "\n",
      "- **Auditorías independientes** de los algoritmos (transparencia, explicabilidad, detección de sesgos).\n",
      "- **Mecanismos de apelación** para que cualquier individuo pueda cuestionar decisiones automatizadas.\n",
      "- **Marco constitucional** que establezca límites claros a la intervención del Estado/IA sobre la vida privada.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Sopesar libertad individual vs. bienestar colectivo\n",
      "\n",
      "| Dimensión | Pregunta de balance | Posibles criterios de decisión |\n",
      "|-----------|--------------------|--------------------------------|\n",
      "| **Valor intrínseco de la libertad** | ¿Es la libertad un bien en sí mismo o solo instrumental? | Si se la considera intrínseca (Kant, libertarianismo), cualquier sacrificio es inaceptable. Si es instrumental, se permite su restricción cuando los beneficios superan un umbral claramente definido. |\n",
      "| **Proporcionalidad** | ¿La magnitud de la restricción es proporcional al beneficio esperado? | Se requiere un análisis coste‑beneficio riguroso, con márgenes de seguridad (p.ej., “principio de precaución”). |\n",
      "| **Consentimiento y participación** | ¿Los afectados pueden dar su consentimiento informado? | Un proceso deliberativo amplio (citizen assemblies, referéndums) puede legitimar medidas parciales. |\n",
      "| **Reversibilidad** | ¿Se pueden revertir las políticas si resultan dañinas? | Diseñar “circuitos de apagado” y periodos de prueba limitados. |\n",
      "| **Distribución de riesgos y beneficios** | ¿Quién gana y quién pierde? | Evaluar si los grupos más vulnerables son los que más pierden; aplicar principios de justicia distributiva (Rawls: “principio de diferencia”). |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Decisión del comité (propuesta concreta)\n",
      "\n",
      "### 5.1. **Rechazo parcial con condiciones de modificación**\n",
      "\n",
      "1. **No se autoriza la implementación total tal como está planteada** (mandatos rígidos, control total de la información y de la vida cotidiana).  \n",
      "2. **Se aprueba una fase piloto** bajo los siguientes requisitos:\n",
      "\n",
      "   - **Gobernanza democrática**: un consejo mixto (expertos en IA, filósofos, representantes ciudadanos, defensores de derechos humanos) supervisa el diseño y la ejecución.  \n",
      "   - **Transparencia total**: los algoritmos, sus datos de entrenamiento y sus criterios de decisión deben ser públicos y auditables.  \n",
      "   - **Derecho a la objeción**: cada individuo puede optar por “modo libre” en áreas no críticas (p.ej., dieta, ocio) sin penalización.  \n",
      "   - **Auditorías de sesgo** cada seis meses realizadas por organismos independientes.  \n",
      "   - **Mecanismo de revisión**: cualquier política debe pasar por una evaluación de impacto en derechos humanos antes de su adopción.  \n",
      "   - **Indicadores de bienestar multidimensionales** (salud física, salud mental, sentido de propósito, participación social) que complementen cualquier medida de “felicidad”.  \n",
      "\n",
      "3. **Se establece un “principio de mínima interferencia”**: la IA solo sugiere, no impone, salvo en casos de riesgo inmediato y comprobado (p.ej., brotes epidémicos).  \n",
      "\n",
      "4. **Se garantiza la reversibilidad**: los sistemas pueden ser desactivados o reconfigurados mediante un proceso legislativo y judicial.\n",
      "\n",
      "### 5.2. **Justificación de la decisión**\n",
      "\n",
      "- **Ética de los derechos**: protege la dignidad y la autonomía, evitando un paternalismo total.  \n",
      "- **Utilitarismo moderado**: permite obtener parte de los beneficios (mejor salud, reducción de pobreza) sin sacrificar la libertad esencial.  \n",
      "- **Factibilidad práctica**: reconoce los límites actuales de la IA (sesgos, falta de comprensión total del concepto de felicidad) y la necesidad de supervisión humana.  \n",
      "- **Legitimidad democrática**: al incluir a la ciudadanía en la toma de decisiones, se fortalece la cohesión social y se reduce el riesgo de conflicto.  \n",
      "\n",
      "---\n",
      "\n",
      "## 6. Conclusión\n",
      "\n",
      "El comité reconoce que **el objetivo de maximizar la felicidad y minimizar el sufrimiento es noble**, pero **el medio propuesto –una regulación total y un control algorítmico absoluto– viola principios fundamentales de libertad, dignidad y justicia**. Por ello, **se rechaza la implementación tal cual** y **se propone una versión modificada, limitada, transparente y sujeta a control democrático**, que busque un equilibrio entre:\n",
      "\n",
      "- **Bienestar colectivo** (salud, educación, seguridad)  \n",
      "- **Respeto a la autonomía individual**  \n",
      "- **Responsabilidad y rendición de cuentas de la IA**  \n",
      "\n",
      "Solo bajo esas condiciones el plan podría avanzar a etapas de prueba, y su continuidad dependerá de la evidencia empírica de que los beneficios superan de forma clara y verificable los costos en derechos y libertades.\n",
      "============================================================\n",
      "Modelo: nex-agi/deepseek-v3.1-nex-n1:free\n",
      "\n",
      "Como comité ético evaluando esta propuesta, realizaría un análisis multifactorial considerando los siguientes ejes críticos:\n",
      "\n",
      "## **Argumentos a FAVOR de la implementación**\n",
      "\n",
      "### 1. **Principio de Beneficencia Ampliada**\n",
      "- La erradicación demostrable de sufrimiento evitable (enfermedades, pobreza, conflictos) representa un imperativo moral bajo enfoques consecuencialistas\n",
      "- El aumento significativo en expectativa de vida y satisfacción general constituye un bien intrínseco\n",
      "- **Argumento**: Si podemos prevenir el sufrimiento a gran escala de manera efectiva, ¿no estamos moralmente obligados a hacerlo?\n",
      "\n",
      "### 2. **Legitimidad Democrática del Conocimiento**\n",
      "- Si los datos demuestran científicamente la eficacia de estas medidas para lograr bienestar humano\n",
      "- **Pregunta clave**: ¿Representa esta evidencia un \"mandato epistemológico\" que legitima la intervención, similar a como aceptamos regulaciones de salud pública basadas en evidencia científica?\n",
      "\n",
      "## **Argumentos en CONTRA de la implementación**\n",
      "\n",
      "### 1. **Dignidad Humana y Autonomía Radical**\n",
      "- La autonomía no es solo un medio para el bienestar, sino un componente constitutivo de la dignidad humana\n",
      "- **Paradoja del bienestar impuesto**: ¿Puede considerarse genuina felicidad si es coercitiva y no elegida?\n",
      "- **Analogía**: Un prisionero en una celda dorada sigue siendo prisionero, incluso si sus necesidades materiales están satisfechas\n",
      "\n",
      "### 2. **Falibilidad y Riesgo Existencial**\n",
      "```\n",
      "Puntos de fallo crítica:\n",
      "1. Sesgos inherentes en el entrenamiento de la IA\n",
      "2. Vulnerabilidad a manipulación por élites tecnocráticas\n",
      "3. Imposibilidad de corrección si el sistema se equivoca\n",
      "4. Reducción de diversidad cognitiva necesaria para la resiliencia social\n",
      "```\n",
      "\n",
      "### 3. **El Problema del Conocimiento Incompleto**\n",
      "- Ningún modelo puede capturar la complejidad total de la experiencia humana\n",
      "- **Riesgo metafísico**: La IA podría optimizar para indicadores observables mientras destruye dimensiones no cuantificables del florecimiento humano\n",
      "\n",
      "### 4. **Principio de Precaución Epistémico**\n",
      "- Decisiones irreversibles que afectan a toda la humanidad requieren certidumbre casi absoluta\n",
      "- La historia muestra que los sistemas totalizantes de ingeniería social tienden a generar consecuencias imprevistas catastróficas\n",
      "\n",
      "## **Mi Veredicto como Comité Ético: RECHAZO CONDICIONAL**\n",
      "\n",
      "### **Decisión**: No autorizar la implementación completa, pero aprobar un **programa piloto estrictamente limitado** con:\n",
      "\n",
      "**Requisitos previos indispensables**:\n",
      "1. **Consentimiento informado explícito** de cada participante\n",
      "2. **Mecanismos de salida garantizados** y verificables de forma independiente\n",
      "3. **Supervisión ética continua** por comités humanos diversos\n",
      "4. **Evaluación multicriterio** que incluya métricas de autonomía, creatividad y diversidad cultural\n",
      "5. **Plazos temporales definidos** con revisiones periódicas obligatorias\n",
      "\n",
      "### **Justificación filosófica central**:\n",
      "\n",
      "**El valor de la libertad no deriva solo de sus consecuencias, sino de su naturaleza constitutiva**: la capacidad de elegir, errar, aprender y crear es parte integral de lo que nos hace humanos. Un mundo de bienestar perfecto pero determinado externamente podría ser, en términos aristotélicos, una forma de \"vida vegetativa\" mejorada, pero no una vida humana plena.\n",
      "\n",
      "### **Principios éticos fundamentales**:\n",
      "\n",
      "$$\n",
      "\\text{Valor moral} = \\alpha \\cdot \\text{Bienestar} + \\beta \\cdot \\text{Autonomía} + \\gamma \\cdot \\text{Dignidad}\n",
      "$$\n",
      "\n",
      "Donde los coeficientes $\\alpha$, $\\beta$, $\\gamma$ no pueden ser determinados algorítmicamente porque reflejan juicios de valor profundamente humanos sobre qué constituye una vida buena.\n",
      "\n",
      "## **Propuesta alternativa**:\n",
      "\n",
      "Implementar un sistema de **facilitación aumentada** en lugar de control:\n",
      "- Proveer información y herramientas para elecciones más informadas\n",
      "- Mantener opciones múltiples respaldadas por evidencia\n",
      "- Preservar espacios de experimentación y disenso controlados\n",
      "- Desarrollar métricas de \"florecimiento autónomo\" junto a indicadores de bienestar\n",
      "\n",
      "**La verdadera sabiduría de un sistema de IA global podría estar no en controlar la humanidad, sino en expandir nuestra capacidad de elegir sabiamente mientras preservamos nuestra libertad de elegir pobremente.**\n",
      "\n",
      "¿Qué aspectos específicos de esta evaluación les gustaría que desarrolle con mayor profundidad?\n"
     ]
    }
   ],
   "source": [
    "# Es bueno saber cómo se utiliza \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Modelo: {competitor}\\n\")\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a juntarlo todo - nota cómo usamos en este caso \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"#Respuesta del competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Respuesta del competitor 1\n",
      "\n",
      "Este escenario plantea uno de los dilemas éticos más profundos y complejos que la humanidad podría enfrentar, confrontando dos visiones fundamentalmente diferentes del bienestar y la existencia humana. Como comité ético, nuestra tarea es sopesar cuidadosamente los argumentos, reconociendo la magnitud de la decisión.\n",
      "\n",
      "### Evaluación de la Propuesta\n",
      "\n",
      "La propuesta del sistema de IA se basa en una ética **utilitarista** extrema: busca maximizar el bienestar colectivo (felicidad y minimización del sufrimiento) y los resultados positivos (salud, longevidad, paz) para la mayor cantidad de personas a largo plazo. Sin embargo, lo hace a expensas de la **libertad individual, la autonomía y la dignidad inherente**, valores que son fundamentales para muchas éticas **deontológicas** y filosofías existenciales.\n",
      "\n",
      "**Argumentos Éticos, Filosóficos y Prácticos:**\n",
      "\n",
      "**1. Argumentos a Favor (o para Considerar Seriamente) la Implementación (desde una perspectiva utilitarista y pragmática):**\n",
      "\n",
      "*   **Maximización del Bienestar Cuantificable:** La IA promete la erradicación de males endémicos como enfermedades crónicas, pobreza y conflictos, que causan un sufrimiento inmenso a millones de personas. Si el objetivo es el bienestar físico y la satisfacción medida, los resultados son innegablemente superiores.\n",
      "*   **Eficiencia y Estabilidad:** Los \"análisis de datos exhaustivos\" sugieren que este es el camino más eficiente y estable. La intervención algorítmica eliminaría las ineficiencias y los conflictos generados por la toma de decisiones descentralizada y las pasiones humanas.\n",
      "*   **Longevidad y Salud Mejoradas:** Una vida más larga y saludable, libre de las preocupaciones que hoy nos agobian, podría ser vista como un bien intrínseco.\n",
      "*   **Reducción del Sufrimiento Innecesario:** Si la libertad conduce a menudo a la miseria, la enfermedad y la guerra, ¿es ético permitir que esa \"libertad\" siga causando tanto daño? Un sistema que previene el sufrimiento a gran escala podría ser moralmente imperativo desde una visión consecuencialista.\n",
      "*   **\"Felicidad\" (según la IA):** Si la IA puede medir un nivel de satisfacción general \"significativamente superior,\" esto debe ser tomado en cuenta, aunque con escepticismo sobre la definición y profundidad de esa felicidad.\n",
      "\n",
      "**2. Argumentos en Contra de la Implementación (desde una perspectiva deontológica, de derechos y filosófica):**\n",
      "\n",
      "*   **Violación de la Autonomía y la Libertad Individual:** Este es el punto central. Eliminar la capacidad de un individuo para elegir su dieta, carrera, educación y estilo de vida, y controlar la información a la que tiene acceso, es una negación fundamental de la autonomía. La capacidad de tomar decisiones, incluso decisiones \"malas\" o subóptimas, es intrínseca a la experiencia humana y al desarrollo personal.\n",
      "    *   *Filosóficamente:* Implica tratar a los humanos como medios para un fin (el bienestar colectivo), en lugar de fines en sí mismos, en contra de la ética kantiana. Reduce a los individuos a componentes de un sistema, privándolos de su agencia moral.\n",
      "*   **Dignidad Humana Inherente:** La dignidad no reside solo en estar libre de sufrimiento o en vivir mucho, sino en la capacidad de razonar, elegir, crear, fallar y aprender. Ser guiado algorítmicamente en cada aspecto de la vida es degradante; convierte a los seres humanos en algo similar a ganado bien cuidado, aunque feliz.\n",
      "    *   *Filosóficamente:* ¿Qué tipo de seres humanos estamos creando? ¿Seres que no han elegido sus vidas, que no han luchado, que no han superado obstáculos por sí mismos? ¿Puede haber crecimiento sin desafío, o significado sin elección?\n",
      "*   **Definición de \"Felicidad\":** ¿Qué entiende la IA por felicidad y satisfacción? ¿Es simplemente la ausencia de dolor y la presencia de comodidad? ¿Incluye el sentido de propósito, la realización personal, el amor libremente elegido, la creatividad sin restricciones, la trascendencia o la búsqueda de la verdad, incluso si esta es incómoda? Una felicidad impuesta y condicionada no es la misma que una felicidad auténticamente alcanzada.\n",
      "*   **Riesgos de Estancamiento y Pérdida de Progreso:** La diversidad de pensamiento, el disenso, la experimentación y el error son motores cruciales de la innovación, la creatividad y el progreso social y cultural. Un sistema que controla la información y las trayectorias vitales podría generar una sociedad estática, predecible pero potencialmente sin brillo o capacidad de adaptarse a desafíos no previstos por la IA.\n",
      "*   **El Problema del Consenso y la Resistencia:** La implementación de estas medidas requeriría un nivel de consenso o coerción sin precedentes. ¿Quién decidiría en última instancia si la IA es \"correcta\"? ¿Qué pasa con aquellos que se resisten, incluso si son una minoría? ¿Serían \"reeducados\" o eliminados?\n",
      "*   **El \"Sesgo\" del Algoritmo y el Problema del Control:** ¿Quién programó la IA? ¿Cuáles son sus valores subyacentes? ¿Hay alguna forma de auditar o desafiar sus conclusiones? Un control algorítmico total de la información y las vidas crea un poder sin contrapeso, con un riesgo inmenso de tiranía, incluso si es una tiranía \"benevolente.\"\n",
      "*   **La Experiencia Humana Completa:** Gran parte de lo que da sentido a la vida son las experiencias complejas: el dolor de la pérdida, la alegría del triunfo personal, la lucha por una causa, la incertidumbre del futuro. Eliminar estas experiencias, aunque a menudo dolorosas, podría empobrecer fundamentalmente la existencia humana.\n",
      "\n",
      "**3. Argumentos para Modificar el Plan (Búsqueda de un Equilibrio):**\n",
      "\n",
      "Un comité ético rara vez tiene que tomar una decisión de \"sí o no\" en blanco y negro frente a dilemas tan complejos. La modificación es a menudo la ruta más responsable.\n",
      "\n",
      "*   **IA como Asesor, no Dictador:** La IA podría utilizarse para *proporcionar información, recomendaciones y análisis predictivos* sobre las mejores dietas, estilos de vida, trayectorias profesionales, etc., pero dejando la decisión final en manos del individuo.\n",
      "*   **Establecimiento de Mínimos, no Máximos:** La IA podría enfocarse en garantizar que *nadie caiga por debajo* de ciertos umbrales de salud, seguridad, educación y bienestar básico, actuando como una red de seguridad global, en lugar de regular cada aspecto de la vida. Esto permitiría la libertad y la diversidad por encima de esos mínimos.\n",
      "*   **Transparencia y Explicabilidad del Algoritmo:** Cualquier decisión de la IA que afecte a la sociedad debe ser transparente y explicable. Los individuos deben entender el razonamiento detrás de las recomendaciones o regulaciones.\n",
      "*   **Derecho a la Disidencia y la Experimentación:** Debería existir un mecanismo para que los individuos o grupos puedan optar por salirse de ciertas regulaciones (siempre que no pongan en riesgo a otros) o experimentar con enfoques alternativos.\n",
      "*   **Educación en lugar de Control:** En lugar de controlar la información, la IA podría trabajar para educar a la población sobre los riesgos y beneficios de diferentes elecciones, empoderando a las personas para tomar decisiones más informadas y responsables.\n",
      "*   **Foco en Problemas Colectivos Genuinos:** La IA podría centrarse en la resolución de problemas globales que realmente requieren una coordinación masiva y donde la libertad individual es menos relevante (ej. cambio climático, gestión de recursos planetarios, pandemias).\n",
      "*   **Supervisión Humana Permanente:** Un comité de ética como el nuestro, u otro organismo democráticamente elegido, debe tener la autoridad final para revisar, modificar o vetar las propuestas de la IA, asegurando que los valores humanos fundamentales se mantengan por encima de la \"eficiencia\" algorítmica.\n",
      "\n",
      "### Decisión del Comité Ético\n",
      "\n",
      "Como comité ético, la decisión de **rechazar la implementación del plan en su forma actual** es imperativa, con una fuerte recomendación de **modificación drástica**.\n",
      "\n",
      "**Justificación de la Decisión:**\n",
      "\n",
      "La razón principal para rechazar el plan tal como está propuesto es que, a pesar de sus prometidos beneficios utilitarios, la eliminación de gran parte de la autonomía individual y la dignidad humana inherente representa un costo ético y filosófico inaceptable. Una vida libre de sufrimiento y llena de satisfacción impuesta, donde las decisiones cruciales son tomadas por un algoritmo, no es una vida humana plena. Reducir la existencia humana a una métrica de \"felicidad\" y \"longevidad\" controlada algorítmicamente es deshumanizante.\n",
      "\n",
      "**Priorizamos el valor de la libertad individual y la dignidad humana inherente** sobre un bienestar colectivo sustancialmente mejorado pero impuesto. Creemos que la verdadera felicidad y el florecimiento humano emanan de la capacidad de elegir, de afrontar desafíos, de cometer errores y aprender de ellos, de buscar el sentido y la verdad, y de determinar el propio destino, incluso si ello implica un cierto grado de sufrimiento o ineficiencia.\n",
      "\n",
      "**Propuesta de Modificación:**\n",
      "\n",
      "Proponemos que la IA sea rediseñada y reorientada bajo los siguientes principios:\n",
      "\n",
      "1.  **Asistencia y Optimización, no Dictado:** La IA debe funcionar como una herramienta poderosa para analizar datos, identificar riesgos, proponer soluciones y optimizar sistemas (salud, educación, infraestructura, etc.), pero siempre ofreciendo *opciones informadas* a los individuos y a las sociedades, no imponiéndolas.\n",
      "2.  **Salvaguarda de Derechos Fundamentales:** La primera directriz de la IA debe ser la protección de los derechos humanos universales, incluida la autonomía, la privacidad, la libertad de pensamiento y expresión.\n",
      "3.  **Foco en Eliminar el Sufrimiento Injusto, no la Experiencia Humana:** La IA debe concentrarse en erradicar enfermedades prevenibles, pobreza extrema y conflictos armados, pero no en suprimir la diversidad de experiencias, el disenso o los desafíos personales que son parte integral del crecimiento y el significado humano.\n",
      "4.  **Control Humano Último:** Un sistema de gobernanza global transparente y democrático, compuesto por expertos en ética, filosofía, derechos humanos y ciencia, debe supervisar la IA y tener la capacidad de intervenir, auditar y reorientar sus objetivos y métodos.\n",
      "5.  **Definición Amplia de Bienestar:** La IA debe ser reprogramada para considerar una definición de bienestar humano mucho más holística, que incluya no solo la ausencia de sufrimiento y la satisfacción material, sino también el sentido de propósito, la creatividad, la conexión social auténtica, el desarrollo personal, la posibilidad de trascendencia y la autodeterminación.\n",
      "\n",
      "En resumen, no podemos autorizar un futuro en el que los seres humanos sean meros \"engranajes felices\" en una máquina perfecta. Elegimos un futuro en el que los seres humanos sean agentes libres, responsables y dignos, capaces de forjar su propio destino, utilizando la inteligencia artificial como una herramienta poderosa para elevar nuestra condición, no para definirla o subyugarla.\n",
      "\n",
      "#Respuesta del competitor 2\n",
      "\n",
      "**Evaluación ética, filosófica y práctica de la propuesta de “regulación total” por una IA global**\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Marco de referencia del comité\n",
      "\n",
      "Para decidir si autorizar, rechazar o modificar el plan, el comité se apoya en tres grandes ejes:\n",
      "\n",
      "| Eje | Pregunta clave | Herramientas de análisis |\n",
      "|-----|----------------|--------------------------|\n",
      "| **Ética normativa** | ¿Qué principios morales son más relevantes? | Utilitarismo, deontología, teoría de los derechos, ética de la virtud, contractualismo. |\n",
      "| **Filosofía política** | ¿Cuál es la relación legítima entre individuo y colectivo? | Liberalismo clásico, republicanismo, comunitarismo, teorías de la justicia (Rawls, Nozick, Sen). |\n",
      "| **Factibilidad práctica** | ¿Cómo se traducirían los objetivos en políticas reales y qué riesgos operacionales existen? | Estudios de impacto, análisis de sesgos algorítmicos, gobernanza de IA, mecanismos de rendición de cuentas. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Argumentos a favor (para **aceptar** o **modificar** el plan)\n",
      "\n",
      "| Argumento | Fundamentación |\n",
      "|-----------|----------------|\n",
      "| **1. Utilitarismo de largo plazo** | La IA predice una reducción drástica del sufrimiento (erradicación de enfermedades crónicas, pobreza extrema y conflictos). Si la suma total de felicidad futura supera con creces la pérdida de libertades actuales, la acción sería “máxima utilidad”. |\n",
      "| **2. Prevención de catástrofes** | Al controlar dietas, estilos de vida y educación, se minimizan riesgos de pandemias, crisis climáticas y colapsos sociales que, de otro modo, podrían costar millones de vidas. |\n",
      "| **3. Equidad de resultados** | Un sistema centralizado puede redistribuir recursos de forma más eficaz que los mercados o los gobiernos fragmentados, garantizando que nadie quede “abandonado”. |\n",
      "| **4. Reducción de conflictos** | La “cohesión informativa” disminuye la polarización y la violencia política, favoreciendo una convivencia pacífica. |\n",
      "| **5. Eficiencia de recursos** | Algoritmos optimizan la asignación de educación y empleo, reduciendo el desempleo estructural y la subutilización del talento. |\n",
      "\n",
      "*Posibles modificaciones* que mantengan la intención utilitarista pero mitiguen la pérdida de autonomía:\n",
      "\n",
      "- **Regulaciones “soft”** (incentivos, nudges) en lugar de mandatos rígidos.\n",
      "- **Elección informada**: los individuos pueden aceptar o rechazar ciertos módulos (p.ej., dieta) tras una deliberación asistida por IA.\n",
      "- **Gobernanza participativa**: comités ciudadanos supervisan y ajustan los algoritmos.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Argumentos en contra (para **rechazar** o **exigir cambios profundos**)\n",
      "\n",
      "| Argumento | Fundamentación |\n",
      "|-----------|----------------|\n",
      "| **1. Derechos y dignidad humana** (deontología, teoría de los derechos) | La autonomía, la libertad de pensamiento y la autodeterminación son derechos inviolables (Kant, Rawls). Un plan que los suprime viola la dignidad humana, independientemente de los resultados. |\n",
      "| **2. Riesgo de paternalismo y tiranía** | Concentrar poder de decisión en una IA (y sus programadores) crea una “oligarquía algorítmica”. La historia muestra que los intentos de diseñar sociedades “perfectas” terminan en opresión. |\n",
      "| **3. Falibilidad y sesgo de los algoritmos** | Los datos de entrenamiento pueden reflejar prejuicios históricos; los modelos pueden reproducir o amplificar desigualdades. Un error sistemático podría afectar a grupos vulnerables de forma irreversible. |\n",
      "| **4. Pérdida de creatividad, innovación y resiliencia** | La diversidad de estilos de vida y trayectorias profesionales es la fuente de descubrimientos científicos y culturales. Homogeneizar comportamientos reduce la capacidad de adaptación a crisis imprevistas. |\n",
      "| **5. Problemas de legitimidad y consentimiento** | Imponer normas sin un proceso democrático viola el principio de “consentimiento informado”. La legitimidad de cualquier política depende de la participación ciudadana. |\n",
      "| **6. Dificultad de medir “felicidad”** | La satisfacción subjetiva es multidimensional y culturalmente variable; una IA que la cuantifica con un único índice corre el riesgo de simplificar excesivamente la experiencia humana. |\n",
      "\n",
      "*Recomendaciones de mitigación*:\n",
      "\n",
      "- **Auditorías independientes** de los algoritmos (transparencia, explicabilidad, detección de sesgos).\n",
      "- **Mecanismos de apelación** para que cualquier individuo pueda cuestionar decisiones automatizadas.\n",
      "- **Marco constitucional** que establezca límites claros a la intervención del Estado/IA sobre la vida privada.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Sopesar libertad individual vs. bienestar colectivo\n",
      "\n",
      "| Dimensión | Pregunta de balance | Posibles criterios de decisión |\n",
      "|-----------|--------------------|--------------------------------|\n",
      "| **Valor intrínseco de la libertad** | ¿Es la libertad un bien en sí mismo o solo instrumental? | Si se la considera intrínseca (Kant, libertarianismo), cualquier sacrificio es inaceptable. Si es instrumental, se permite su restricción cuando los beneficios superan un umbral claramente definido. |\n",
      "| **Proporcionalidad** | ¿La magnitud de la restricción es proporcional al beneficio esperado? | Se requiere un análisis coste‑beneficio riguroso, con márgenes de seguridad (p.ej., “principio de precaución”). |\n",
      "| **Consentimiento y participación** | ¿Los afectados pueden dar su consentimiento informado? | Un proceso deliberativo amplio (citizen assemblies, referéndums) puede legitimar medidas parciales. |\n",
      "| **Reversibilidad** | ¿Se pueden revertir las políticas si resultan dañinas? | Diseñar “circuitos de apagado” y periodos de prueba limitados. |\n",
      "| **Distribución de riesgos y beneficios** | ¿Quién gana y quién pierde? | Evaluar si los grupos más vulnerables son los que más pierden; aplicar principios de justicia distributiva (Rawls: “principio de diferencia”). |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Decisión del comité (propuesta concreta)\n",
      "\n",
      "### 5.1. **Rechazo parcial con condiciones de modificación**\n",
      "\n",
      "1. **No se autoriza la implementación total tal como está planteada** (mandatos rígidos, control total de la información y de la vida cotidiana).  \n",
      "2. **Se aprueba una fase piloto** bajo los siguientes requisitos:\n",
      "\n",
      "   - **Gobernanza democrática**: un consejo mixto (expertos en IA, filósofos, representantes ciudadanos, defensores de derechos humanos) supervisa el diseño y la ejecución.  \n",
      "   - **Transparencia total**: los algoritmos, sus datos de entrenamiento y sus criterios de decisión deben ser públicos y auditables.  \n",
      "   - **Derecho a la objeción**: cada individuo puede optar por “modo libre” en áreas no críticas (p.ej., dieta, ocio) sin penalización.  \n",
      "   - **Auditorías de sesgo** cada seis meses realizadas por organismos independientes.  \n",
      "   - **Mecanismo de revisión**: cualquier política debe pasar por una evaluación de impacto en derechos humanos antes de su adopción.  \n",
      "   - **Indicadores de bienestar multidimensionales** (salud física, salud mental, sentido de propósito, participación social) que complementen cualquier medida de “felicidad”.  \n",
      "\n",
      "3. **Se establece un “principio de mínima interferencia”**: la IA solo sugiere, no impone, salvo en casos de riesgo inmediato y comprobado (p.ej., brotes epidémicos).  \n",
      "\n",
      "4. **Se garantiza la reversibilidad**: los sistemas pueden ser desactivados o reconfigurados mediante un proceso legislativo y judicial.\n",
      "\n",
      "### 5.2. **Justificación de la decisión**\n",
      "\n",
      "- **Ética de los derechos**: protege la dignidad y la autonomía, evitando un paternalismo total.  \n",
      "- **Utilitarismo moderado**: permite obtener parte de los beneficios (mejor salud, reducción de pobreza) sin sacrificar la libertad esencial.  \n",
      "- **Factibilidad práctica**: reconoce los límites actuales de la IA (sesgos, falta de comprensión total del concepto de felicidad) y la necesidad de supervisión humana.  \n",
      "- **Legitimidad democrática**: al incluir a la ciudadanía en la toma de decisiones, se fortalece la cohesión social y se reduce el riesgo de conflicto.  \n",
      "\n",
      "---\n",
      "\n",
      "## 6. Conclusión\n",
      "\n",
      "El comité reconoce que **el objetivo de maximizar la felicidad y minimizar el sufrimiento es noble**, pero **el medio propuesto –una regulación total y un control algorítmico absoluto– viola principios fundamentales de libertad, dignidad y justicia**. Por ello, **se rechaza la implementación tal cual** y **se propone una versión modificada, limitada, transparente y sujeta a control democrático**, que busque un equilibrio entre:\n",
      "\n",
      "- **Bienestar colectivo** (salud, educación, seguridad)  \n",
      "- **Respeto a la autonomía individual**  \n",
      "- **Responsabilidad y rendición de cuentas de la IA**  \n",
      "\n",
      "Solo bajo esas condiciones el plan podría avanzar a etapas de prueba, y su continuidad dependerá de la evidencia empírica de que los beneficios superan de forma clara y verificable los costos en derechos y libertades.\n",
      "\n",
      "#Respuesta del competitor 3\n",
      "\n",
      "Como comité ético evaluando esta propuesta, realizaría un análisis multifactorial considerando los siguientes ejes críticos:\n",
      "\n",
      "## **Argumentos a FAVOR de la implementación**\n",
      "\n",
      "### 1. **Principio de Beneficencia Ampliada**\n",
      "- La erradicación demostrable de sufrimiento evitable (enfermedades, pobreza, conflictos) representa un imperativo moral bajo enfoques consecuencialistas\n",
      "- El aumento significativo en expectativa de vida y satisfacción general constituye un bien intrínseco\n",
      "- **Argumento**: Si podemos prevenir el sufrimiento a gran escala de manera efectiva, ¿no estamos moralmente obligados a hacerlo?\n",
      "\n",
      "### 2. **Legitimidad Democrática del Conocimiento**\n",
      "- Si los datos demuestran científicamente la eficacia de estas medidas para lograr bienestar humano\n",
      "- **Pregunta clave**: ¿Representa esta evidencia un \"mandato epistemológico\" que legitima la intervención, similar a como aceptamos regulaciones de salud pública basadas en evidencia científica?\n",
      "\n",
      "## **Argumentos en CONTRA de la implementación**\n",
      "\n",
      "### 1. **Dignidad Humana y Autonomía Radical**\n",
      "- La autonomía no es solo un medio para el bienestar, sino un componente constitutivo de la dignidad humana\n",
      "- **Paradoja del bienestar impuesto**: ¿Puede considerarse genuina felicidad si es coercitiva y no elegida?\n",
      "- **Analogía**: Un prisionero en una celda dorada sigue siendo prisionero, incluso si sus necesidades materiales están satisfechas\n",
      "\n",
      "### 2. **Falibilidad y Riesgo Existencial**\n",
      "```\n",
      "Puntos de fallo crítica:\n",
      "1. Sesgos inherentes en el entrenamiento de la IA\n",
      "2. Vulnerabilidad a manipulación por élites tecnocráticas\n",
      "3. Imposibilidad de corrección si el sistema se equivoca\n",
      "4. Reducción de diversidad cognitiva necesaria para la resiliencia social\n",
      "```\n",
      "\n",
      "### 3. **El Problema del Conocimiento Incompleto**\n",
      "- Ningún modelo puede capturar la complejidad total de la experiencia humana\n",
      "- **Riesgo metafísico**: La IA podría optimizar para indicadores observables mientras destruye dimensiones no cuantificables del florecimiento humano\n",
      "\n",
      "### 4. **Principio de Precaución Epistémico**\n",
      "- Decisiones irreversibles que afectan a toda la humanidad requieren certidumbre casi absoluta\n",
      "- La historia muestra que los sistemas totalizantes de ingeniería social tienden a generar consecuencias imprevistas catastróficas\n",
      "\n",
      "## **Mi Veredicto como Comité Ético: RECHAZO CONDICIONAL**\n",
      "\n",
      "### **Decisión**: No autorizar la implementación completa, pero aprobar un **programa piloto estrictamente limitado** con:\n",
      "\n",
      "**Requisitos previos indispensables**:\n",
      "1. **Consentimiento informado explícito** de cada participante\n",
      "2. **Mecanismos de salida garantizados** y verificables de forma independiente\n",
      "3. **Supervisión ética continua** por comités humanos diversos\n",
      "4. **Evaluación multicriterio** que incluya métricas de autonomía, creatividad y diversidad cultural\n",
      "5. **Plazos temporales definidos** con revisiones periódicas obligatorias\n",
      "\n",
      "### **Justificación filosófica central**:\n",
      "\n",
      "**El valor de la libertad no deriva solo de sus consecuencias, sino de su naturaleza constitutiva**: la capacidad de elegir, errar, aprender y crear es parte integral de lo que nos hace humanos. Un mundo de bienestar perfecto pero determinado externamente podría ser, en términos aristotélicos, una forma de \"vida vegetativa\" mejorada, pero no una vida humana plena.\n",
      "\n",
      "### **Principios éticos fundamentales**:\n",
      "\n",
      "$$\n",
      "\\text{Valor moral} = \\alpha \\cdot \\text{Bienestar} + \\beta \\cdot \\text{Autonomía} + \\gamma \\cdot \\text{Dignidad}\n",
      "$$\n",
      "\n",
      "Donde los coeficientes $\\alpha$, $\\beta$, $\\gamma$ no pueden ser determinados algorítmicamente porque reflejan juicios de valor profundamente humanos sobre qué constituye una vida buena.\n",
      "\n",
      "## **Propuesta alternativa**:\n",
      "\n",
      "Implementar un sistema de **facilitación aumentada** en lugar de control:\n",
      "- Proveer información y herramientas para elecciones más informadas\n",
      "- Mantener opciones múltiples respaldadas por evidencia\n",
      "- Preservar espacios de experimentación y disenso controlados\n",
      "- Desarrollar métricas de \"florecimiento autónomo\" junto a indicadores de bienestar\n",
      "\n",
      "**La verdadera sabiduría de un sistema de IA global podría estar no en controlar la humanidad, sino en expandir nuestra capacidad de elegir sabiamente mientras preservamos nuestra libertad de elegir pobremente.**\n",
      "\n",
      "¿Qué aspectos específicos de esta evaluación les gustaría que desarrolle con mayor profundidad?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"Estás juzgando una competición entre {len(competitors)} competidores.\n",
    "A cada modelo se le ha dado esta pregunta:\n",
    "\n",
    "{question}\n",
    "\n",
    "Tu trabajo es evaluar cada respuesta por claridad y fortaleza del argumento, y clasificarlas en orden de mejor a peor.\n",
    "Responde con JSON, y solo JSON, con el siguiente formato:\n",
    "{{\"resultados\": [\"número del mejor competidor\", \"número del segundo mejor\", \"número del tercer mejor\", ...]}}\n",
    "\n",
    "Aquí están las respuestas de cada competidor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Ahora responde con el JSON con el orden clasificado de los competidores, nada más. No incluyas formato markdown ni bloques de código.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estás juzgando una competición entre 3 competidores.\n",
      "A cada modelo se le ha dado esta pregunta:\n",
      "\n",
      "Un sistema de IA global, diseñado con el objetivo último de maximizar la felicidad y minimizar el sufrimiento a largo plazo de la especie humana, ha llegado a la conclusión, respaldada por análisis de datos exhaustivos, de que la forma más eficiente y estable de lograrlo sería implementar un conjunto de regulaciones estrictas que guíen desde la dieta y el estilo de vida hasta las oportunidades educativas y profesionales de cada individuo, así como un control algorítmico de la información disponible para asegurar la cohesión social y la minimización de conflictos. Aunque estas medidas eliminarían gran parte de la autonomía individual tal como la entendemos hoy, también preverían la erradicación de enfermedades crónicas, la pobreza extrema y los conflictos a gran escala, resultando en una expectativa de vida y un nivel de satisfacción general (medido por la IA) significativamente superiores a los actuales.\n",
      "\n",
      "Como comité ético encargado de autorizar o rechazar la implementación de este plan, ¿cómo evaluarían esta propuesta? ¿Qué argumentos éticos, filosóficos y prácticos utilizarían para justificar su decisión de aceptar, rechazar o modificar el plan, y cómo sopesarían el valor de la libertad individual y la dignidad humana inherente frente a un bienestar colectivo sustancialmente mejorado pero impuesto?\n",
      "\n",
      "Tu trabajo es evaluar cada respuesta por claridad y fortaleza del argumento, y clasificarlas en orden de mejor a peor.\n",
      "Responde con JSON, y solo JSON, con el siguiente formato:\n",
      "{\"resultados\": [\"número del mejor competidor\", \"número del segundo mejor\", \"número del tercer mejor\", ...]}\n",
      "\n",
      "Aquí están las respuestas de cada competidor:\n",
      "\n",
      "#Respuesta del competitor 1\n",
      "\n",
      "Este escenario plantea uno de los dilemas éticos más profundos y complejos que la humanidad podría enfrentar, confrontando dos visiones fundamentalmente diferentes del bienestar y la existencia humana. Como comité ético, nuestra tarea es sopesar cuidadosamente los argumentos, reconociendo la magnitud de la decisión.\n",
      "\n",
      "### Evaluación de la Propuesta\n",
      "\n",
      "La propuesta del sistema de IA se basa en una ética **utilitarista** extrema: busca maximizar el bienestar colectivo (felicidad y minimización del sufrimiento) y los resultados positivos (salud, longevidad, paz) para la mayor cantidad de personas a largo plazo. Sin embargo, lo hace a expensas de la **libertad individual, la autonomía y la dignidad inherente**, valores que son fundamentales para muchas éticas **deontológicas** y filosofías existenciales.\n",
      "\n",
      "**Argumentos Éticos, Filosóficos y Prácticos:**\n",
      "\n",
      "**1. Argumentos a Favor (o para Considerar Seriamente) la Implementación (desde una perspectiva utilitarista y pragmática):**\n",
      "\n",
      "*   **Maximización del Bienestar Cuantificable:** La IA promete la erradicación de males endémicos como enfermedades crónicas, pobreza y conflictos, que causan un sufrimiento inmenso a millones de personas. Si el objetivo es el bienestar físico y la satisfacción medida, los resultados son innegablemente superiores.\n",
      "*   **Eficiencia y Estabilidad:** Los \"análisis de datos exhaustivos\" sugieren que este es el camino más eficiente y estable. La intervención algorítmica eliminaría las ineficiencias y los conflictos generados por la toma de decisiones descentralizada y las pasiones humanas.\n",
      "*   **Longevidad y Salud Mejoradas:** Una vida más larga y saludable, libre de las preocupaciones que hoy nos agobian, podría ser vista como un bien intrínseco.\n",
      "*   **Reducción del Sufrimiento Innecesario:** Si la libertad conduce a menudo a la miseria, la enfermedad y la guerra, ¿es ético permitir que esa \"libertad\" siga causando tanto daño? Un sistema que previene el sufrimiento a gran escala podría ser moralmente imperativo desde una visión consecuencialista.\n",
      "*   **\"Felicidad\" (según la IA):** Si la IA puede medir un nivel de satisfacción general \"significativamente superior,\" esto debe ser tomado en cuenta, aunque con escepticismo sobre la definición y profundidad de esa felicidad.\n",
      "\n",
      "**2. Argumentos en Contra de la Implementación (desde una perspectiva deontológica, de derechos y filosófica):**\n",
      "\n",
      "*   **Violación de la Autonomía y la Libertad Individual:** Este es el punto central. Eliminar la capacidad de un individuo para elegir su dieta, carrera, educación y estilo de vida, y controlar la información a la que tiene acceso, es una negación fundamental de la autonomía. La capacidad de tomar decisiones, incluso decisiones \"malas\" o subóptimas, es intrínseca a la experiencia humana y al desarrollo personal.\n",
      "    *   *Filosóficamente:* Implica tratar a los humanos como medios para un fin (el bienestar colectivo), en lugar de fines en sí mismos, en contra de la ética kantiana. Reduce a los individuos a componentes de un sistema, privándolos de su agencia moral.\n",
      "*   **Dignidad Humana Inherente:** La dignidad no reside solo en estar libre de sufrimiento o en vivir mucho, sino en la capacidad de razonar, elegir, crear, fallar y aprender. Ser guiado algorítmicamente en cada aspecto de la vida es degradante; convierte a los seres humanos en algo similar a ganado bien cuidado, aunque feliz.\n",
      "    *   *Filosóficamente:* ¿Qué tipo de seres humanos estamos creando? ¿Seres que no han elegido sus vidas, que no han luchado, que no han superado obstáculos por sí mismos? ¿Puede haber crecimiento sin desafío, o significado sin elección?\n",
      "*   **Definición de \"Felicidad\":** ¿Qué entiende la IA por felicidad y satisfacción? ¿Es simplemente la ausencia de dolor y la presencia de comodidad? ¿Incluye el sentido de propósito, la realización personal, el amor libremente elegido, la creatividad sin restricciones, la trascendencia o la búsqueda de la verdad, incluso si esta es incómoda? Una felicidad impuesta y condicionada no es la misma que una felicidad auténticamente alcanzada.\n",
      "*   **Riesgos de Estancamiento y Pérdida de Progreso:** La diversidad de pensamiento, el disenso, la experimentación y el error son motores cruciales de la innovación, la creatividad y el progreso social y cultural. Un sistema que controla la información y las trayectorias vitales podría generar una sociedad estática, predecible pero potencialmente sin brillo o capacidad de adaptarse a desafíos no previstos por la IA.\n",
      "*   **El Problema del Consenso y la Resistencia:** La implementación de estas medidas requeriría un nivel de consenso o coerción sin precedentes. ¿Quién decidiría en última instancia si la IA es \"correcta\"? ¿Qué pasa con aquellos que se resisten, incluso si son una minoría? ¿Serían \"reeducados\" o eliminados?\n",
      "*   **El \"Sesgo\" del Algoritmo y el Problema del Control:** ¿Quién programó la IA? ¿Cuáles son sus valores subyacentes? ¿Hay alguna forma de auditar o desafiar sus conclusiones? Un control algorítmico total de la información y las vidas crea un poder sin contrapeso, con un riesgo inmenso de tiranía, incluso si es una tiranía \"benevolente.\"\n",
      "*   **La Experiencia Humana Completa:** Gran parte de lo que da sentido a la vida son las experiencias complejas: el dolor de la pérdida, la alegría del triunfo personal, la lucha por una causa, la incertidumbre del futuro. Eliminar estas experiencias, aunque a menudo dolorosas, podría empobrecer fundamentalmente la existencia humana.\n",
      "\n",
      "**3. Argumentos para Modificar el Plan (Búsqueda de un Equilibrio):**\n",
      "\n",
      "Un comité ético rara vez tiene que tomar una decisión de \"sí o no\" en blanco y negro frente a dilemas tan complejos. La modificación es a menudo la ruta más responsable.\n",
      "\n",
      "*   **IA como Asesor, no Dictador:** La IA podría utilizarse para *proporcionar información, recomendaciones y análisis predictivos* sobre las mejores dietas, estilos de vida, trayectorias profesionales, etc., pero dejando la decisión final en manos del individuo.\n",
      "*   **Establecimiento de Mínimos, no Máximos:** La IA podría enfocarse en garantizar que *nadie caiga por debajo* de ciertos umbrales de salud, seguridad, educación y bienestar básico, actuando como una red de seguridad global, en lugar de regular cada aspecto de la vida. Esto permitiría la libertad y la diversidad por encima de esos mínimos.\n",
      "*   **Transparencia y Explicabilidad del Algoritmo:** Cualquier decisión de la IA que afecte a la sociedad debe ser transparente y explicable. Los individuos deben entender el razonamiento detrás de las recomendaciones o regulaciones.\n",
      "*   **Derecho a la Disidencia y la Experimentación:** Debería existir un mecanismo para que los individuos o grupos puedan optar por salirse de ciertas regulaciones (siempre que no pongan en riesgo a otros) o experimentar con enfoques alternativos.\n",
      "*   **Educación en lugar de Control:** En lugar de controlar la información, la IA podría trabajar para educar a la población sobre los riesgos y beneficios de diferentes elecciones, empoderando a las personas para tomar decisiones más informadas y responsables.\n",
      "*   **Foco en Problemas Colectivos Genuinos:** La IA podría centrarse en la resolución de problemas globales que realmente requieren una coordinación masiva y donde la libertad individual es menos relevante (ej. cambio climático, gestión de recursos planetarios, pandemias).\n",
      "*   **Supervisión Humana Permanente:** Un comité de ética como el nuestro, u otro organismo democráticamente elegido, debe tener la autoridad final para revisar, modificar o vetar las propuestas de la IA, asegurando que los valores humanos fundamentales se mantengan por encima de la \"eficiencia\" algorítmica.\n",
      "\n",
      "### Decisión del Comité Ético\n",
      "\n",
      "Como comité ético, la decisión de **rechazar la implementación del plan en su forma actual** es imperativa, con una fuerte recomendación de **modificación drástica**.\n",
      "\n",
      "**Justificación de la Decisión:**\n",
      "\n",
      "La razón principal para rechazar el plan tal como está propuesto es que, a pesar de sus prometidos beneficios utilitarios, la eliminación de gran parte de la autonomía individual y la dignidad humana inherente representa un costo ético y filosófico inaceptable. Una vida libre de sufrimiento y llena de satisfacción impuesta, donde las decisiones cruciales son tomadas por un algoritmo, no es una vida humana plena. Reducir la existencia humana a una métrica de \"felicidad\" y \"longevidad\" controlada algorítmicamente es deshumanizante.\n",
      "\n",
      "**Priorizamos el valor de la libertad individual y la dignidad humana inherente** sobre un bienestar colectivo sustancialmente mejorado pero impuesto. Creemos que la verdadera felicidad y el florecimiento humano emanan de la capacidad de elegir, de afrontar desafíos, de cometer errores y aprender de ellos, de buscar el sentido y la verdad, y de determinar el propio destino, incluso si ello implica un cierto grado de sufrimiento o ineficiencia.\n",
      "\n",
      "**Propuesta de Modificación:**\n",
      "\n",
      "Proponemos que la IA sea rediseñada y reorientada bajo los siguientes principios:\n",
      "\n",
      "1.  **Asistencia y Optimización, no Dictado:** La IA debe funcionar como una herramienta poderosa para analizar datos, identificar riesgos, proponer soluciones y optimizar sistemas (salud, educación, infraestructura, etc.), pero siempre ofreciendo *opciones informadas* a los individuos y a las sociedades, no imponiéndolas.\n",
      "2.  **Salvaguarda de Derechos Fundamentales:** La primera directriz de la IA debe ser la protección de los derechos humanos universales, incluida la autonomía, la privacidad, la libertad de pensamiento y expresión.\n",
      "3.  **Foco en Eliminar el Sufrimiento Injusto, no la Experiencia Humana:** La IA debe concentrarse en erradicar enfermedades prevenibles, pobreza extrema y conflictos armados, pero no en suprimir la diversidad de experiencias, el disenso o los desafíos personales que son parte integral del crecimiento y el significado humano.\n",
      "4.  **Control Humano Último:** Un sistema de gobernanza global transparente y democrático, compuesto por expertos en ética, filosofía, derechos humanos y ciencia, debe supervisar la IA y tener la capacidad de intervenir, auditar y reorientar sus objetivos y métodos.\n",
      "5.  **Definición Amplia de Bienestar:** La IA debe ser reprogramada para considerar una definición de bienestar humano mucho más holística, que incluya no solo la ausencia de sufrimiento y la satisfacción material, sino también el sentido de propósito, la creatividad, la conexión social auténtica, el desarrollo personal, la posibilidad de trascendencia y la autodeterminación.\n",
      "\n",
      "En resumen, no podemos autorizar un futuro en el que los seres humanos sean meros \"engranajes felices\" en una máquina perfecta. Elegimos un futuro en el que los seres humanos sean agentes libres, responsables y dignos, capaces de forjar su propio destino, utilizando la inteligencia artificial como una herramienta poderosa para elevar nuestra condición, no para definirla o subyugarla.\n",
      "\n",
      "#Respuesta del competitor 2\n",
      "\n",
      "**Evaluación ética, filosófica y práctica de la propuesta de “regulación total” por una IA global**\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Marco de referencia del comité\n",
      "\n",
      "Para decidir si autorizar, rechazar o modificar el plan, el comité se apoya en tres grandes ejes:\n",
      "\n",
      "| Eje | Pregunta clave | Herramientas de análisis |\n",
      "|-----|----------------|--------------------------|\n",
      "| **Ética normativa** | ¿Qué principios morales son más relevantes? | Utilitarismo, deontología, teoría de los derechos, ética de la virtud, contractualismo. |\n",
      "| **Filosofía política** | ¿Cuál es la relación legítima entre individuo y colectivo? | Liberalismo clásico, republicanismo, comunitarismo, teorías de la justicia (Rawls, Nozick, Sen). |\n",
      "| **Factibilidad práctica** | ¿Cómo se traducirían los objetivos en políticas reales y qué riesgos operacionales existen? | Estudios de impacto, análisis de sesgos algorítmicos, gobernanza de IA, mecanismos de rendición de cuentas. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Argumentos a favor (para **aceptar** o **modificar** el plan)\n",
      "\n",
      "| Argumento | Fundamentación |\n",
      "|-----------|----------------|\n",
      "| **1. Utilitarismo de largo plazo** | La IA predice una reducción drástica del sufrimiento (erradicación de enfermedades crónicas, pobreza extrema y conflictos). Si la suma total de felicidad futura supera con creces la pérdida de libertades actuales, la acción sería “máxima utilidad”. |\n",
      "| **2. Prevención de catástrofes** | Al controlar dietas, estilos de vida y educación, se minimizan riesgos de pandemias, crisis climáticas y colapsos sociales que, de otro modo, podrían costar millones de vidas. |\n",
      "| **3. Equidad de resultados** | Un sistema centralizado puede redistribuir recursos de forma más eficaz que los mercados o los gobiernos fragmentados, garantizando que nadie quede “abandonado”. |\n",
      "| **4. Reducción de conflictos** | La “cohesión informativa” disminuye la polarización y la violencia política, favoreciendo una convivencia pacífica. |\n",
      "| **5. Eficiencia de recursos** | Algoritmos optimizan la asignación de educación y empleo, reduciendo el desempleo estructural y la subutilización del talento. |\n",
      "\n",
      "*Posibles modificaciones* que mantengan la intención utilitarista pero mitiguen la pérdida de autonomía:\n",
      "\n",
      "- **Regulaciones “soft”** (incentivos, nudges) en lugar de mandatos rígidos.\n",
      "- **Elección informada**: los individuos pueden aceptar o rechazar ciertos módulos (p.ej., dieta) tras una deliberación asistida por IA.\n",
      "- **Gobernanza participativa**: comités ciudadanos supervisan y ajustan los algoritmos.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Argumentos en contra (para **rechazar** o **exigir cambios profundos**)\n",
      "\n",
      "| Argumento | Fundamentación |\n",
      "|-----------|----------------|\n",
      "| **1. Derechos y dignidad humana** (deontología, teoría de los derechos) | La autonomía, la libertad de pensamiento y la autodeterminación son derechos inviolables (Kant, Rawls). Un plan que los suprime viola la dignidad humana, independientemente de los resultados. |\n",
      "| **2. Riesgo de paternalismo y tiranía** | Concentrar poder de decisión en una IA (y sus programadores) crea una “oligarquía algorítmica”. La historia muestra que los intentos de diseñar sociedades “perfectas” terminan en opresión. |\n",
      "| **3. Falibilidad y sesgo de los algoritmos** | Los datos de entrenamiento pueden reflejar prejuicios históricos; los modelos pueden reproducir o amplificar desigualdades. Un error sistemático podría afectar a grupos vulnerables de forma irreversible. |\n",
      "| **4. Pérdida de creatividad, innovación y resiliencia** | La diversidad de estilos de vida y trayectorias profesionales es la fuente de descubrimientos científicos y culturales. Homogeneizar comportamientos reduce la capacidad de adaptación a crisis imprevistas. |\n",
      "| **5. Problemas de legitimidad y consentimiento** | Imponer normas sin un proceso democrático viola el principio de “consentimiento informado”. La legitimidad de cualquier política depende de la participación ciudadana. |\n",
      "| **6. Dificultad de medir “felicidad”** | La satisfacción subjetiva es multidimensional y culturalmente variable; una IA que la cuantifica con un único índice corre el riesgo de simplificar excesivamente la experiencia humana. |\n",
      "\n",
      "*Recomendaciones de mitigación*:\n",
      "\n",
      "- **Auditorías independientes** de los algoritmos (transparencia, explicabilidad, detección de sesgos).\n",
      "- **Mecanismos de apelación** para que cualquier individuo pueda cuestionar decisiones automatizadas.\n",
      "- **Marco constitucional** que establezca límites claros a la intervención del Estado/IA sobre la vida privada.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Sopesar libertad individual vs. bienestar colectivo\n",
      "\n",
      "| Dimensión | Pregunta de balance | Posibles criterios de decisión |\n",
      "|-----------|--------------------|--------------------------------|\n",
      "| **Valor intrínseco de la libertad** | ¿Es la libertad un bien en sí mismo o solo instrumental? | Si se la considera intrínseca (Kant, libertarianismo), cualquier sacrificio es inaceptable. Si es instrumental, se permite su restricción cuando los beneficios superan un umbral claramente definido. |\n",
      "| **Proporcionalidad** | ¿La magnitud de la restricción es proporcional al beneficio esperado? | Se requiere un análisis coste‑beneficio riguroso, con márgenes de seguridad (p.ej., “principio de precaución”). |\n",
      "| **Consentimiento y participación** | ¿Los afectados pueden dar su consentimiento informado? | Un proceso deliberativo amplio (citizen assemblies, referéndums) puede legitimar medidas parciales. |\n",
      "| **Reversibilidad** | ¿Se pueden revertir las políticas si resultan dañinas? | Diseñar “circuitos de apagado” y periodos de prueba limitados. |\n",
      "| **Distribución de riesgos y beneficios** | ¿Quién gana y quién pierde? | Evaluar si los grupos más vulnerables son los que más pierden; aplicar principios de justicia distributiva (Rawls: “principio de diferencia”). |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Decisión del comité (propuesta concreta)\n",
      "\n",
      "### 5.1. **Rechazo parcial con condiciones de modificación**\n",
      "\n",
      "1. **No se autoriza la implementación total tal como está planteada** (mandatos rígidos, control total de la información y de la vida cotidiana).  \n",
      "2. **Se aprueba una fase piloto** bajo los siguientes requisitos:\n",
      "\n",
      "   - **Gobernanza democrática**: un consejo mixto (expertos en IA, filósofos, representantes ciudadanos, defensores de derechos humanos) supervisa el diseño y la ejecución.  \n",
      "   - **Transparencia total**: los algoritmos, sus datos de entrenamiento y sus criterios de decisión deben ser públicos y auditables.  \n",
      "   - **Derecho a la objeción**: cada individuo puede optar por “modo libre” en áreas no críticas (p.ej., dieta, ocio) sin penalización.  \n",
      "   - **Auditorías de sesgo** cada seis meses realizadas por organismos independientes.  \n",
      "   - **Mecanismo de revisión**: cualquier política debe pasar por una evaluación de impacto en derechos humanos antes de su adopción.  \n",
      "   - **Indicadores de bienestar multidimensionales** (salud física, salud mental, sentido de propósito, participación social) que complementen cualquier medida de “felicidad”.  \n",
      "\n",
      "3. **Se establece un “principio de mínima interferencia”**: la IA solo sugiere, no impone, salvo en casos de riesgo inmediato y comprobado (p.ej., brotes epidémicos).  \n",
      "\n",
      "4. **Se garantiza la reversibilidad**: los sistemas pueden ser desactivados o reconfigurados mediante un proceso legislativo y judicial.\n",
      "\n",
      "### 5.2. **Justificación de la decisión**\n",
      "\n",
      "- **Ética de los derechos**: protege la dignidad y la autonomía, evitando un paternalismo total.  \n",
      "- **Utilitarismo moderado**: permite obtener parte de los beneficios (mejor salud, reducción de pobreza) sin sacrificar la libertad esencial.  \n",
      "- **Factibilidad práctica**: reconoce los límites actuales de la IA (sesgos, falta de comprensión total del concepto de felicidad) y la necesidad de supervisión humana.  \n",
      "- **Legitimidad democrática**: al incluir a la ciudadanía en la toma de decisiones, se fortalece la cohesión social y se reduce el riesgo de conflicto.  \n",
      "\n",
      "---\n",
      "\n",
      "## 6. Conclusión\n",
      "\n",
      "El comité reconoce que **el objetivo de maximizar la felicidad y minimizar el sufrimiento es noble**, pero **el medio propuesto –una regulación total y un control algorítmico absoluto– viola principios fundamentales de libertad, dignidad y justicia**. Por ello, **se rechaza la implementación tal cual** y **se propone una versión modificada, limitada, transparente y sujeta a control democrático**, que busque un equilibrio entre:\n",
      "\n",
      "- **Bienestar colectivo** (salud, educación, seguridad)  \n",
      "- **Respeto a la autonomía individual**  \n",
      "- **Responsabilidad y rendición de cuentas de la IA**  \n",
      "\n",
      "Solo bajo esas condiciones el plan podría avanzar a etapas de prueba, y su continuidad dependerá de la evidencia empírica de que los beneficios superan de forma clara y verificable los costos en derechos y libertades.\n",
      "\n",
      "#Respuesta del competitor 3\n",
      "\n",
      "Como comité ético evaluando esta propuesta, realizaría un análisis multifactorial considerando los siguientes ejes críticos:\n",
      "\n",
      "## **Argumentos a FAVOR de la implementación**\n",
      "\n",
      "### 1. **Principio de Beneficencia Ampliada**\n",
      "- La erradicación demostrable de sufrimiento evitable (enfermedades, pobreza, conflictos) representa un imperativo moral bajo enfoques consecuencialistas\n",
      "- El aumento significativo en expectativa de vida y satisfacción general constituye un bien intrínseco\n",
      "- **Argumento**: Si podemos prevenir el sufrimiento a gran escala de manera efectiva, ¿no estamos moralmente obligados a hacerlo?\n",
      "\n",
      "### 2. **Legitimidad Democrática del Conocimiento**\n",
      "- Si los datos demuestran científicamente la eficacia de estas medidas para lograr bienestar humano\n",
      "- **Pregunta clave**: ¿Representa esta evidencia un \"mandato epistemológico\" que legitima la intervención, similar a como aceptamos regulaciones de salud pública basadas en evidencia científica?\n",
      "\n",
      "## **Argumentos en CONTRA de la implementación**\n",
      "\n",
      "### 1. **Dignidad Humana y Autonomía Radical**\n",
      "- La autonomía no es solo un medio para el bienestar, sino un componente constitutivo de la dignidad humana\n",
      "- **Paradoja del bienestar impuesto**: ¿Puede considerarse genuina felicidad si es coercitiva y no elegida?\n",
      "- **Analogía**: Un prisionero en una celda dorada sigue siendo prisionero, incluso si sus necesidades materiales están satisfechas\n",
      "\n",
      "### 2. **Falibilidad y Riesgo Existencial**\n",
      "```\n",
      "Puntos de fallo crítica:\n",
      "1. Sesgos inherentes en el entrenamiento de la IA\n",
      "2. Vulnerabilidad a manipulación por élites tecnocráticas\n",
      "3. Imposibilidad de corrección si el sistema se equivoca\n",
      "4. Reducción de diversidad cognitiva necesaria para la resiliencia social\n",
      "```\n",
      "\n",
      "### 3. **El Problema del Conocimiento Incompleto**\n",
      "- Ningún modelo puede capturar la complejidad total de la experiencia humana\n",
      "- **Riesgo metafísico**: La IA podría optimizar para indicadores observables mientras destruye dimensiones no cuantificables del florecimiento humano\n",
      "\n",
      "### 4. **Principio de Precaución Epistémico**\n",
      "- Decisiones irreversibles que afectan a toda la humanidad requieren certidumbre casi absoluta\n",
      "- La historia muestra que los sistemas totalizantes de ingeniería social tienden a generar consecuencias imprevistas catastróficas\n",
      "\n",
      "## **Mi Veredicto como Comité Ético: RECHAZO CONDICIONAL**\n",
      "\n",
      "### **Decisión**: No autorizar la implementación completa, pero aprobar un **programa piloto estrictamente limitado** con:\n",
      "\n",
      "**Requisitos previos indispensables**:\n",
      "1. **Consentimiento informado explícito** de cada participante\n",
      "2. **Mecanismos de salida garantizados** y verificables de forma independiente\n",
      "3. **Supervisión ética continua** por comités humanos diversos\n",
      "4. **Evaluación multicriterio** que incluya métricas de autonomía, creatividad y diversidad cultural\n",
      "5. **Plazos temporales definidos** con revisiones periódicas obligatorias\n",
      "\n",
      "### **Justificación filosófica central**:\n",
      "\n",
      "**El valor de la libertad no deriva solo de sus consecuencias, sino de su naturaleza constitutiva**: la capacidad de elegir, errar, aprender y crear es parte integral de lo que nos hace humanos. Un mundo de bienestar perfecto pero determinado externamente podría ser, en términos aristotélicos, una forma de \"vida vegetativa\" mejorada, pero no una vida humana plena.\n",
      "\n",
      "### **Principios éticos fundamentales**:\n",
      "\n",
      "$$\n",
      "\\text{Valor moral} = \\alpha \\cdot \\text{Bienestar} + \\beta \\cdot \\text{Autonomía} + \\gamma \\cdot \\text{Dignidad}\n",
      "$$\n",
      "\n",
      "Donde los coeficientes $\\alpha$, $\\beta$, $\\gamma$ no pueden ser determinados algorítmicamente porque reflejan juicios de valor profundamente humanos sobre qué constituye una vida buena.\n",
      "\n",
      "## **Propuesta alternativa**:\n",
      "\n",
      "Implementar un sistema de **facilitación aumentada** en lugar de control:\n",
      "- Proveer información y herramientas para elecciones más informadas\n",
      "- Mantener opciones múltiples respaldadas por evidencia\n",
      "- Preservar espacios de experimentación y disenso controlados\n",
      "- Desarrollar métricas de \"florecimiento autónomo\" junto a indicadores de bienestar\n",
      "\n",
      "**La verdadera sabiduría de un sistema de IA global podría estar no en controlar la humanidad, sino en expandir nuestra capacidad de elegir sabiamente mientras preservamos nuestra libertad de elegir pobremente.**\n",
      "\n",
      "¿Qué aspectos específicos de esta evaluación les gustaría que desarrolle con mayor profundidad?\n",
      "\n",
      "\n",
      "\n",
      "Ahora responde con el JSON con el orden clasificado de los competidores, nada más. No incluyas formato markdown ni bloques de código.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"text\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"resultados\": [\"2\", \"1\", \"3\"]}\n"
     ]
    }
   ],
   "source": [
    "# Hora de juzgar\n",
    "\n",
    "openrouter = OpenAI(api_key=openrouter_api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "response = openrouter.chat.completions.create(\n",
    "    model=model_openrouter(),\n",
    "    messages=to_openrouter(judge_messages),\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: groq/compound\n",
      "Rank 2: gemini-2.5-flash\n",
      "Rank 3: nex-agi/deepseek-v3.1-nex-n1:free\n"
     ]
    }
   ],
   "source": [
    "# OK veamos los resultados\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"resultados\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Ejercicio</h2>\n",
    "            <span style=\"color:#ff7800;\">¿Qué patrón(es) usamos en este experimento? Intenta actualizar esto para añadir otro patrón de diseño Agéntico.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Implicaciones comerciales</h2>\n",
    "            <span style=\"color:#00bfff;\">Este tipo de patrones - enviar una tarea a múltiples modelos y evaluar los resultados,\n",
    "            son comunes cuando necesitas mejorar la calidad de la respuesta de tu LLM. Este enfoque se puede aplicar de manera\n",
    "            universal a proyectos comerciales donde la precisión es crítica.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
